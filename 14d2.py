#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import requests
import json
import time
import os
from datetime import datetime
import pandas as pd
import numpy as np
import pytz
from concurrent.futures import ThreadPoolExecutor, as_completed
from math import floor

class OKXMonitor:
    def __init__(self):
        # --- æ ¸å¿ƒé…ç½® ---
        self.base_url = "https://www.okx.com"
        self.server_jiang_key = 'SCT281228TBF1BQU3KUJ4vLRkykhzIE80e'
        
        # --- ç­–ç•¥å‚æ•° ---
        self.MACD_VOLUME_THRESHOLD = 10_000_000
        self.ATR_MULTIPLIER = 2.0
        self.MAX_CANDLES_AGO = 5
        
        # --- ç³»ç»Ÿé…ç½® ---
        self.session = self._create_session()
        self.timezone = pytz.timezone('Asia/Shanghai')
        self.state_file = 'watchlist_state.json'
        self.CONCURRENCY_LIMIT = 10
        self.STRICT_CONCURRENCY_LIMIT = 5
        self.request_timestamps = []
        self.RATE_LIMIT_COUNT = 18
        self.RATE_LIMIT_WINDOW = 2000
        self.debug_logs = [] # ç”¨äºå­˜å‚¨è°ƒè¯•æ—¥å¿—

    # ... [æ‰€æœ‰æœªæ”¹åŠ¨çš„è¾…åŠ©å‡½æ•°ã€æ•°æ®è·å–ã€æŒ‡æ ‡è®¡ç®—ã€è¯„åˆ†ç³»ç»Ÿå‡½æ•°éƒ½ä¿æŒä¸å˜] ...
    def _create_session(self):
        session = requests.Session()
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept-Language': 'en-US,en;q=0.9',
        }
        session.headers.update(headers)
        return session
    
    def get_current_time_str(self):
        return datetime.now(self.timezone).strftime('%Y-%m-%d %H:%M:%S')

    def _rate_limiter(self):
        now = int(time.time() * 1000)
        self.request_timestamps = [ts for ts in self.request_timestamps if now - ts < self.RATE_LIMIT_WINDOW]
        if len(self.request_timestamps) >= self.RATE_LIMIT_COUNT:
            oldest_request_time = self.request_timestamps[0]
            time_passed = now - oldest_request_time
            delay = (self.RATE_LIMIT_WINDOW - time_passed) / 1000
            if delay > 0:
                time.sleep(delay + 0.05)
        self.request_timestamps.append(int(time.time() * 1000))

    def fetch_with_retry(self, url, params, retries=5, timeout=15):
        self._rate_limiter()
        for i in range(retries):
            try:
                response = self.session.get(url, params=params, timeout=timeout)
                if response.status_code == 429:
                    raise Exception(f"è¯·æ±‚é¢‘ç‡è¿‡é«˜ (429)")
                response.raise_for_status()
                data = response.json()
                if data.get('code') == '0':
                    return data.get('data')
                raise Exception(f"APIè¿”å›é”™è¯¯: {data.get('msg', 'æœªçŸ¥é”™è¯¯')}")
            except Exception as e:
                if i == retries - 1:
                    return None
                delay = 2**i + np.random.rand()
                time.sleep(delay)
        return None

    def send_notification(self, title, content):
        if not self.server_jiang_key:
            print(f"[{self.get_current_time_str()}] æœªé…ç½®SERVER_JIANG_KEYï¼Œé€šçŸ¥å°†æ‰“å°åˆ°æ§åˆ¶å°ã€‚")
            print(f"æ ‡é¢˜: {title}\nå†…å®¹:\n{content}")
            return
        desp = content
        try:
            url = f"https://sctapi.ftqq.com/{self.server_jiang_key}.send"
            data = {'title': title, 'desp': desp}
            response = requests.post(url, data=data, timeout=30)
            response.raise_for_status()
            result = response.json()
            if result.get('code') == 0:
                print(f"[{self.get_current_time_str()}] é€šçŸ¥å‘é€æˆåŠŸ: {title}")
            else:
                print(f"[{self.get_current_time_str()}] é€šçŸ¥å‘é€å¤±è´¥: {result}")
        except Exception as e:
            print(f"[{self.get_current_time_str()}] å‘é€é€šçŸ¥æ—¶å‡ºé”™: {e}")
    
    def get_perpetual_instruments(self):
        data = self.fetch_with_retry(f"{self.base_url}/api/v5/public/instruments", {'instType': 'SWAP'})
        if data:
            instruments = [inst['instId'] for inst in data if inst['state'] == 'live' and inst['instId'].endswith('-USDT-SWAP')]
            print(f"[{self.get_current_time_str()}] è·å–åˆ° {len(instruments)} ä¸ªæ´»è·ƒçš„USDTæ°¸ç»­åˆçº¦")
            return instruments
        print(f"[{self.get_current_time_str()}] è·å–äº¤æ˜“å¯¹å¤±è´¥ã€‚")
        return []

    def get_kline_data(self, inst_id, bar='1H', limit=100):
        data = self.fetch_with_retry(f"{self.base_url}/api/v5/market/candles", {'instId': inst_id, 'bar': bar, 'limit': limit})
        return data[::-1] if data else []

    def get_ticker_data(self, inst_id):
        data = self.fetch_with_retry(f"{self.base_url}/api/v5/market/ticker", {'instId': inst_id})
        if data and data[0]:
            ticker = data[0]
            last_price = float(ticker.get('last', 0))
            open_24h = float(ticker.get('open24h', 0))
            if open_24h > 0:
                return {'price_change_24h': ((last_price - open_24h) / open_24h) * 100}
        return {'price_change_24h': 0}

    def fetch_all_data_for_instrument(self, inst_id):
        with ThreadPoolExecutor(max_workers=3) as executor:
            future_h1 = executor.submit(self.get_kline_data, inst_id, '1H', 112 + 12)
            future_h4 = executor.submit(self.get_kline_data, inst_id, '4H', 105 + 4)
            future_d1 = executor.submit(self.get_kline_data, inst_id, '1D', 102 + 2)
            h1, h4, d1 = future_h1.result(), future_h4.result(), future_d1.result()
        if h1 and h4 and d1:
            return inst_id, {'h1': h1, 'h4': h4, 'd1': d1}
        return inst_id, None

    def _parse_klines_to_df(self, klines):
        if not klines: return pd.DataFrame()
        df = pd.DataFrame(klines, columns=['ts', 'open', 'high', 'low', 'close', 'vol', 'volCcy', 'volCcyQuote', 'confirm'])
        for col in df.columns:
            df[col] = pd.to_numeric(df[col])
        return df

    def calculate_macd(self, prices_series, fast=12, slow=26, signal=9):
        if len(prices_series) < slow: return pd.DataFrame()
        ema_fast = prices_series.ewm(span=fast, adjust=False).mean()
        ema_slow = prices_series.ewm(span=slow, adjust=False).mean()
        macd_line = ema_fast - ema_slow
        signal_line = macd_line.ewm(span=signal, adjust=False).mean()
        histogram = macd_line - signal_line
        return pd.DataFrame({'macd': macd_line, 'signal': signal_line, 'histogram': histogram})

    def calculate_atr(self, df, period=14):
        if df.empty or len(df) < period + 1: return pd.Series(dtype=float)
        high_low = df['high'] - df['low']
        high_close = (df['high'] - df['close'].shift()).abs()
        low_close = (df['low'] - df['close'].shift()).abs()
        tr = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)
        return tr.ewm(span=period, adjust=False).mean()
    
    def calculate_bollinger_bands(self, df, period=20, std_dev=2):
        if len(df) < period: return {}
        sma = df['close'].rolling(window=period).mean().iloc[-1]
        std = df['close'].rolling(window=period).std().iloc[-1]
        upper = sma + (std * std_dev)
        lower = sma - (std * std_dev)
        bandwidth = (upper - lower) / sma if sma > 0 else 0
        return {'upper': upper, 'lower': lower, 'bandwidth': bandwidth}

    def _get_change(self, df, period):
        if df is not None and len(df) > period:
            latest_close = df['close'].iloc[-1]
            past_close = df['close'].iloc[-1 - period]
            if past_close > 0:
                return ((latest_close - past_close) / past_close) * 100
        return None

    def calculate_rs_score(self, inst_df, btc_df, eth_df):
        periods = [5, 10, 20]
        excess_performances = []
        for period in periods:
            inst_change = self._get_change(inst_df, period)
            btc_change = self._get_change(btc_df, period)
            eth_change = self._get_change(eth_df, period)
            if inst_change is None or btc_change is None or eth_change is None:
                return None
            benchmark_change = max(btc_change, eth_change)
            excess_performances.append(inst_change - benchmark_change)
        
        weighted_excess = (excess_performances[0] * 3 + excess_performances[1] * 2 + excess_performances[2] * 1) / 6
        raw_score = 50 + weighted_excess * 2.5
        return max(0, min(100, round(raw_score)))

    def calculate_market_leadership_score(self, inst_df, btc_df, eth_df):
        if len(inst_df) < 60: return None
        weights = {'rs': 40, 'resilience': 30, 'capital_flow': 20, 'trend_quality': 10}
        rs_score = self.calculate_rs_score(inst_df, btc_df, eth_df) or 0
        rs_component = rs_score * (weights['rs'] / 100)
        inst_returns = inst_df['close'].pct_change().iloc[1:]
        btc_returns = btc_df['close'].pct_change().iloc[1:]
        down_day_returns = inst_returns[btc_returns < -0.02]
        resilience_score = 50
        if not down_day_returns.empty:
            avg_inst_return_on_down_days = down_day_returns.mean()
            resilience_score = 50 + (avg_inst_return_on_down_days * 1000)
        resilience_component = max(0, min(100, resilience_score)) * (weights['resilience'] / 100)
        obv = (np.sign(inst_df['close'].diff()) * inst_df['vol']).fillna(0).cumsum()
        obv_sma20 = obv.rolling(20).mean().iloc[-1]
        obv_sma50 = obv.rolling(50).mean().iloc[-1]
        obv_score = 100 if obv_sma20 > obv_sma50 else 0
        vol_sma20 = inst_df['vol'].rolling(20).mean().iloc[-1]
        vol_sma50 = inst_df['vol'].rolling(50).mean().iloc[-1]
        vol_score = 100 if vol_sma20 > vol_sma50 else 0
        capital_flow_component = ((obv_score + vol_score) / 2) * (weights['capital_flow'] / 100)
        daily_returns = inst_df['close'].pct_change().dropna()
        std_dev = daily_returns.std()
        volatility_score = max(0, 100 - (std_dev * 2000))
        peak = inst_df['close'].expanding(min_periods=1).max()
        drawdown = (inst_df['close'] - peak) / peak
        max_drawdown = drawdown.min()
        drawdown_score = max(0, 100 - (abs(max_drawdown) * 200))
        trend_quality_component = ((volatility_score + drawdown_score) / 2) * (weights['trend_quality'] / 100)
        total_score = rs_component + resilience_component + capital_flow_component + trend_quality_component
        return max(0, min(100, round(total_score)))

    def calculate_startup_quality_score(self, opp, metrics):
        score = 0
        weights = {'volume': 30, 'momentum': 25, 'relativeStrength': 15, 'maDistance': 15, 'confirmation': 10, 'volatility': 5}
        vol_ratio = metrics['volume'] / metrics['avg_volume'] if metrics['avg_volume'] > 0 else 1
        vol_score = max(0, min(100, (vol_ratio - 1) * 50))
        growth_rate = (metrics['d1_hist'] - metrics['d1_prev_hist']) / abs(metrics['d1_prev_hist']) if metrics['d1_prev_hist'] != 0 else 0
        momentum_score = max(0, min(100, abs(growth_rate) * 100))
        rs_score_val = opp.get('rs_score', 50)
        ma_dist = (metrics['price'] - metrics['ema60']) / metrics['price'] if metrics['ema60'] else 0
        ma_score = max(0, (1 - abs(ma_dist) * 5) * 100)
        conf_score = min(100, (abs(metrics['h4_hist']) / metrics['price']) * 20000)
        volatility_score = max(0, (1 - metrics['bandwidth']) * 200)
        score += vol_score * weights['volume']
        score += momentum_score * weights['momentum']
        score += rs_score_val * weights['relativeStrength']
        score += ma_score * weights['maDistance']
        score += conf_score * weights['confirmation']
        score += volatility_score * weights['volatility']
        return round(score / 100)

    def calculate_continuation_quality_score(self, opp, d1_df, h4_df, d1_macd, h4_macd):
        weights = {'rs': 40, 'trendHealth': 25, 'volume': 25, 'volatility': 10}
        rs_component = (opp.get('rs_score', 0)) * (weights['rs'] / 100)
        price = d1_df['close'].iloc[-1]
        macd_pos_score = min(100, (abs(d1_macd['signal'].iloc[-1]) / price) * 3000)
        duration_score = min(100, (opp.get('trend_duration_days', 0) / 30) * 100)
        magnitude_score = min(100, (abs(opp.get('trend_change_pct', 0)) / 100) * 100)
        trend_health_component = ((macd_pos_score + duration_score + magnitude_score) / 3) * (weights['trendHealth'] / 100)
        volume_component = 0
        last_h4_cross = self.find_last_cross_info(h4_macd)
        if last_h4_cross and last_h4_cross['index'] > 0:
            idx = last_h4_cross['index']
            pullback_candles = h4_df.iloc[idx:]
            if len(pullback_candles) > 0 and idx >= len(pullback_candles):
                impulse_candles = h4_df.iloc[idx - len(pullback_candles):idx]
                pullback_avg_vol = pullback_candles['vol'].mean()
                impulse_avg_vol = impulse_candles['vol'].mean()
                if impulse_avg_vol > 0:
                    vol_contraction_score = max(0, (1 - (pullback_avg_vol / impulse_avg_vol))) * 100
                    volume_component = vol_contraction_score * (weights['volume'] / 100)
        h4_bands = self.calculate_bollinger_bands(h4_df)
        volatility_score = max(0, (1 - h4_bands.get('bandwidth', 1)) * 150)
        volatility_component = min(100, volatility_score) * (weights['volatility'] / 100)
        total_score = rs_component + trend_health_component + volume_component + volatility_component
        return round(total_score)
    
    def find_last_cross_info(self, macd_df):
        if len(macd_df) < 2: return None
        macds = macd_df.to_dict('records')
        last_cross_type = 'golden' if macds[-1]['macd'] > macds[-1]['signal'] else 'death'
        for i in range(len(macds) - 2, -1, -1):
            current_cross_type = 'golden' if macds[i]['macd'] > macds[i]['signal'] else 'death'
            if current_cross_type != last_cross_type:
                return {'type': last_cross_type, 'index': i + 1}
        return {'type': last_cross_type, 'index': 0}

    def find_last_dea_zero_cross_info(self, macd_df, lookback=100):
        if len(macd_df) < 2: return None
        macds = macd_df.to_dict('records')
        start = max(0, len(macds) - 1 - lookback)
        for i in range(len(macds) - 2, start -1, -1):
            if macds[i]['signal'] <= 0 and macds[i+1]['signal'] > 0:
                return {'type': 'bullish', 'index': i + 1}
            if macds[i]['signal'] >= 0 and macds[i+1]['signal'] < 0:
                return {'type': 'bearish', 'index': i + 1}
        return None

    def get_signal_freshness_info(self, df, macd_df, cross_type, atr_s):
        last_cross = self.find_last_cross_info(macd_df)
        if not last_cross or last_cross['type'] != cross_type:
            return {'is_fresh': False, 'reason': f"æœªæ‰¾åˆ°{cross_type}"}
        idx = last_cross['index']
        candles_ago = len(df) - 1 - idx
        if candles_ago > self.MAX_CANDLES_AGO:
            return {'is_fresh': False, 'reason': f"ä¿¡å·è¿‡ä¹…({candles_ago} > {self.MAX_CANDLES_AGO})"}
        if idx >= len(atr_s) or atr_s.empty:
            return {'is_fresh': False, 'reason': "ATRä¸è¶³"}
        signal_price = df['close'].iloc[idx]
        current_price = df['close'].iloc[-1]
        atr_at_signal = atr_s.iloc[idx]
        if atr_at_signal > 0 and abs(current_price - signal_price) > (self.ATR_MULTIPLIER * atr_at_signal):
            return {'is_fresh': False, 'reason': f"ä»·æ ¼æ³¢åŠ¨è¿‡å¤§(>{self.ATR_MULTIPLIER}å€ATR)"}
        return {'is_fresh': True, 'reason': 'æ–°é²œ'}

    def check_freshness_since_zero_cross(self, df, macd_df, cross_type, atr_s):
        zero_cross = self.find_last_dea_zero_cross_info(macd_df)
        if not zero_cross or zero_cross['type'] != cross_type:
            return {'is_fresh': False, 'reason': 'æœªæ‰¾åˆ°0è½´ç©¿è¶Š'}
        idx = zero_cross['index']
        if idx >= len(atr_s) or atr_s.empty:
            return {'is_fresh': False, 'reason': "ATRä¸è¶³"}
        cross_price = df['close'].iloc[idx]
        current_price = df['close'].iloc[-1]
        atr_at_cross = atr_s.iloc[idx]
        if atr_at_cross > 0 and abs(current_price - cross_price) > (self.ATR_MULTIPLIER * atr_at_cross):
            return {'is_fresh': False, 'reason': f"ç©¿è¶Š0è½´åä»·æ ¼æ³¢åŠ¨è¿‡å¤§(>{self.ATR_MULTIPLIER}å€ATR)"}
        return {'is_fresh': True, 'reason': 'ç©¿è¶Š0è½´ä¸”æ–°é²œ'}

    # --- NEW: Helper for debug logging ---
    def _log_debug(self, debug_info, category, name, cond, val_obj, res):
        if category not in debug_info['checks']:
            debug_info['checks'][category] = {'final_result': False, 'steps': []}
        
        val_str = ""
        if isinstance(val_obj, dict) and 'reason' in val_obj:
            val_str = f"{val_obj['is_fresh']} ({val_obj['reason']})"
        elif isinstance(val_obj, bool):
            val_str = str(val_obj)
        elif isinstance(val_obj, (int, float)):
            val_str = f"{val_obj:.4g}"
        else:
            val_str = str(val_obj)
            
        res_icon = 'âœ…' if res else 'âŒ'
        
        debug_info['checks'][category]['steps'].append({
            'name': name, 'cond': cond, 'val': val_str, 'res': res_icon
        })
        
    def analyze_instrument(self, inst_id, snapshot_data, is_historical=False):
        debug_info = {'inst_id': inst_id, 'leader_score': None, 'rs_score': None, 'checks': {}}
        try:
            h1_df = self._parse_klines_to_df(snapshot_data['h1'])
            h4_df = self._parse_klines_to_df(snapshot_data['h4'])
            d1_df = self._parse_klines_to_df(snapshot_data['d1'])
            btc_d1_df = self._parse_klines_to_df(snapshot_data['btc']['d1'])
            eth_d1_df = self._parse_klines_to_df(snapshot_data['eth']['d1'])

            if len(h1_df) < 24 or len(d1_df) < 60: return None
            
            daily_volume = h1_df['volCcyQuote'].iloc[-24:].sum()
            vol_check = daily_volume >= self.MACD_VOLUME_THRESHOLD
            self._log_debug(debug_info, 'åŸºç¡€è¿‡æ»¤', '24Hæˆäº¤é¢', f"> {self.MACD_VOLUME_THRESHOLD/1e6:.0f}M", f"{daily_volume/1e6:.2f}M", vol_check)
            if not vol_check:
                if not is_historical: self.debug_logs.append(debug_info)
                return None
            
            d1_macd = self.calculate_macd(d1_df['close'])
            h4_macd = self.calculate_macd(h4_df['close'])
            h1_macd = self.calculate_macd(h1_df['close'])
            d1_atr = self.calculate_atr(d1_df)
            h4_atr = self.calculate_atr(h4_df)
            if d1_macd.empty or h4_macd.empty or h1_macd.empty: return None
            
            rs_score = self.calculate_rs_score(d1_df, btc_d1_df, eth_d1_df)
            leader_score = self.calculate_market_leadership_score(d1_df, btc_d1_df, eth_d1_df)
            debug_info.update({'leader_score': leader_score, 'rs_score': rs_score})

            result_base = {'inst_id': inst_id, 'rs_score': rs_score, 'leader_score': leader_score, 'volume': daily_volume}
            
            if is_historical:
                result_base['signalTime'] = h1_df['ts'].iloc[-1]
                result_base['signalPrice'] = h1_df['close'].iloc[-1]

            dea_cross_info = self.find_last_dea_zero_cross_info(d1_macd)
            if dea_cross_info and dea_cross_info['index'] < len(d1_df):
                idx = dea_cross_info['index']
                current_ts = result_base.get('signalTime', time.time() * 1000)
                result_base['trend_change_pct'] = ((d1_df['close'].iloc[-1] - d1_df['close'].iloc[idx]) / d1_df['close'].iloc[idx]) * 100
                result_base['trend_duration_days'] = (current_ts / 1000 - d1_df['ts'].iloc[idx]/1000) / (3600*24)
            
            d1_last, d1_prev = d1_macd.iloc[-1], d1_macd.iloc[-2]
            h4_last, h4_prev = h4_macd.iloc[-1], h4_macd.iloc[-2]
            h1_last, h1_prev = h1_macd.iloc[-1], h1_macd.iloc[-2]
            
            # --- Start Logging Checks ---
            
            # 1. Trend Signals
            form_A_long_info = self.find_last_dea_zero_cross_info(d1_macd, self.MAX_CANDLES_AGO)
            form_A_long = form_A_long_info and form_A_long_info['type'] == 'bullish'
            self._log_debug(debug_info, 'å¤šå¤´å¯åŠ¨', 'å½¢æ€A(è¿‘æœŸç©¿0è½´)', 'true', form_A_long, form_A_long)
            form_B_long_info = self.check_freshness_since_zero_cross(d1_df, d1_macd, 'bullish', d1_atr)
            self._log_debug(debug_info, 'å¤šå¤´å¯åŠ¨', 'å½¢æ€B(ç©¿è½´åæ–°é²œ)', 'true', form_B_long_info, form_B_long_info['is_fresh'])
            momentum_C_long = d1_last['macd'] > d1_last['signal'] and d1_last['histogram'] > d1_prev['histogram']
            self._log_debug(debug_info, 'å¤šå¤´å¯åŠ¨', 'åŠ¨èƒ½C(é‡‘å‰+å¢å¼º)', 'true', momentum_C_long, momentum_C_long)
            
            if (form_A_long or form_B_long_info['is_fresh']) and momentum_C_long:
                h4_ok_long = h4_last['macd'] > h4_last['signal'] and h4_last['histogram'] > h4_prev['histogram']
                self._log_debug(debug_info, 'å¤šå¤´å¯åŠ¨', '4H ç¡®è®¤', 'é‡‘å‰+å¢å¼º', h4_ok_long, h4_ok_long)
                debug_info['checks']['å¤šå¤´å¯åŠ¨']['final_result'] = 'Long Trend' if h4_ok_long else False
                if not is_historical: self.debug_logs.append(debug_info)
                
                if h4_ok_long:
                    metrics = { 'volume': daily_volume, 'avg_volume': d1_df['volCcyQuote'].iloc[-20:].mean(), 'd1_hist': d1_last['histogram'], 'd1_prev_hist': d1_prev['histogram'], 'h4_hist': h4_last['histogram'], 'price': d1_df['close'].iloc[-1], 'ema60': d1_df['close'].ewm(span=60, adjust=False).mean().iloc[-1], 'bandwidth': self.calculate_bollinger_bands(d1_df).get('bandwidth', 1) }
                    score = self.calculate_startup_quality_score(result_base, metrics)
                    return {**result_base, 'type': 'Long Trend', 'quality_score': score}
                else:
                    return {**result_base, 'type': 'Long Watchlist', 'quality_score': None}

            # ... (Similar logging for Short Trend)
            
            # 2. Continuation Signals
            is_stable_bull = d1_last['macd'] > 0 and d1_last['signal'] > 0 and (d1_macd['signal'].iloc[-5:] > 0).all()
            self._log_debug(debug_info, 'é¡ºåŠ¿å¤šå¤´', 'D1 å¼ºè¶‹åŠ¿', '0è½´ä¸Šç¨³å®š', is_stable_bull, is_stable_bull)
            if is_stable_bull:
                base_opp = None
                h4_fresh_info = self.get_signal_freshness_info(h4_df, h4_macd, 'golden', h4_atr)
                self._log_debug(debug_info, 'é¡ºåŠ¿å¤šå¤´', '4H æ–°é²œé‡‘å‰', 'true', h4_fresh_info, h4_fresh_info['is_fresh'])
                is_h1_golden_cross = h1_last['macd'] > h1_last['signal'] and h1_prev['macd'] <= h1_prev['signal']
                self._log_debug(debug_info, 'é¡ºåŠ¿å¤šå¤´', '1H åˆšåˆšé‡‘å‰', 'true', is_h1_golden_cross, is_h1_golden_cross)
                
                if h4_fresh_info['is_fresh'] and is_h1_golden_cross:
                    base_opp = {**result_base, 'type': 'Long Continuation'}
                
                is_h4_hist_rising = h4_last['histogram'] > h4_prev['histogram']
                self._log_debug(debug_info, 'é¡ºåŠ¿å¤šå¤´', '4H å›è°ƒå®‰å…¨', 'åŠ¨èƒ½è¡°ç«­/åè½¬', is_h4_hist_rising, is_h4_hist_rising)
                is_h1_hist_rising = h1_last['histogram'] > h1_prev['histogram']
                self._log_debug(debug_info, 'é¡ºåŠ¿å¤šå¤´', '1H å›è°ƒåŠ¨èƒ½', 'å¢å¼º', is_h1_hist_rising, is_h1_hist_rising)

                if not base_opp and is_h1_golden_cross and is_h4_hist_rising and is_h1_hist_rising:
                    base_opp = {**result_base, 'type': 'Long Pullback'}
                
                if base_opp:
                    debug_info['checks']['é¡ºåŠ¿å¤šå¤´']['final_result'] = base_opp['type']
                    base_opp['quality_score'] = self.calculate_continuation_quality_score(base_opp, d1_df, h4_df, d1_macd, h4_macd)
                    
                    if dea_cross_info and dea_cross_info['type'] == 'bullish' and dea_cross_info['index'] < len(d1_df):
                        # ... (Phoenix signal logic with logging)
                        klines_since_cross = d1_df.iloc[dea_cross_info['index']:]
                        price_at_zero_cross = klines_since_cross['close'].iloc[0]
                        peak_price = klines_since_cross['high'].max()
                        initial_rally_range = peak_price - price_at_zero_cross
                        current_drawdown = peak_price - d1_df['close'].iloc[-1]
                        current_retracement_pct = (current_drawdown / initial_rally_range) * 100 if initial_rally_range > 0 else 0
                        is_deep_retracement = current_retracement_pct > 70
                        self._log_debug(debug_info, 'å‡¤å‡°ä¿¡å·', 'æ ¸å¿ƒå‰æ: æ·±åº¦å›æ’¤', '> 70%', f"{current_retracement_pct:.1f}%", is_deep_retracement)
                        if is_deep_retracement:
                            initial_rally_pct = ((peak_price - price_at_zero_cross) / price_at_zero_cross) * 100
                            has_strength = initial_rally_pct > 15
                            self._log_debug(debug_info, 'å‡¤å‡°ä¿¡å·', 'å¥åº·æ£€æŸ¥1: è¶‹åŠ¿å¼ºåº¦', '> 15%', f"{initial_rally_pct:.1f}%", has_strength)
                            
                            bands_history = d1_df['close'].rolling(20).std() / d1_df['close'].rolling(20).mean()
                            low_vol_threshold = bands_history.quantile(0.3)
                            current_bw = self.calculate_bollinger_bands(d1_df).get('bandwidth', 1)
                            is_vol_low = current_bw < low_vol_threshold
                            self._log_debug(debug_info, 'å‡¤å‡°ä¿¡å·', 'å¥åº·æ£€æŸ¥2: æ³¢åŠ¨æ”¶ç¼©', f"< {low_vol_threshold:.4f}", f"{current_bw:.4f}", is_vol_low)

                            if has_strength and is_vol_low:
                                base_opp['type'] = 'Long Phoenix'
                                debug_info['checks']['å‡¤å‡°ä¿¡å·']['final_result'] = base_opp['type']
                    
                    if not is_historical: self.debug_logs.append(debug_info)
                    return base_opp

            # ... (Similar logic and logging for Short Continuation)
            
            if not is_historical: self.debug_logs.append(debug_info)
            return None
        except Exception as e:
            # print(f"Error in analyze_instrument for {inst_id}: {e}")
            if not is_historical: self.debug_logs.append(debug_info)
            return None

    def get_strategy_explanation(self):
        return """
---
### **ç­–ç•¥è¯´æ˜**

#### **è¯„åˆ†ä½“ç³»**
- **ğŸ† å¸‚åœºé¢†è¢–åˆ† (Leader Score)**: ç»¼åˆè¯„ä¼°å¸ç§çš„â€œé¾™å¤´â€ç‰¹è´¨ã€‚åˆ†æ•°è¶Šé«˜ï¼Œé¾™å¤´ç›¸è¶Šå¼ºã€‚
  - **æ„æˆ**: ç›¸å¯¹å¼ºåº¦(40%), å›è°ƒæŠ—æ€§(30%), èµ„é‡‘æµ(20%), è¶‹åŠ¿è´¨é‡(10%).
- **ğŸš€ å¯åŠ¨ä¿¡å·è´¨é‡åˆ†**: è¡¡é‡è¶‹åŠ¿**èµ·ç‚¹**çš„å¼ºåº¦å’Œå¯é æ€§ã€‚
  - **æ„æˆ**: æˆäº¤é‡(30%), åŠ¨èƒ½(25%), ç›¸å¯¹å¼ºåº¦(15%), å‡çº¿è·ç¦»(15%), ç¡®è®¤åº¦(10%), æ³¢åŠ¨æ€§(5%).
- **â¡ï¸ å»¶ç»­/å›è°ƒè´¨é‡åˆ†**: è¡¡é‡åœ¨**å·²ç¡®ç«‹è¶‹åŠ¿ä¸­**ä»‹å…¥ç‚¹çš„â€œæ€§ä»·æ¯”â€ã€‚
  - **æ„æˆ**: ç›¸å¯¹å¼ºåº¦(40%), è¶‹åŠ¿å¥åº·åº¦(25%), å›è°ƒç¼©é‡(25%), æ³¢åŠ¨æ”¶ç¼©(10%).

#### **é€šç”¨è§„åˆ™ (æ‰€æœ‰ä¿¡å·å‰æ)**
- **æˆäº¤é‡**: ä¿¡å·å‡ºç°æ—¶ï¼Œè¯¥å¸ç§çš„24å°æ—¶æˆäº¤é¢å¿…é¡» **> 1000ä¸‡ USDT**ã€‚

---
### **ä¿¡å·ç±»å‹ä¸æ ¸å¿ƒæ¡ä»¶**

#### **ğŸš€ å¤šå¤´å¯åŠ¨ (Long Trend)**
*   **ç›®æ ‡**: æ•æ‰æ–°ä¸€è½®ä¸Šæ¶¨è¶‹åŠ¿çš„**èµ·ç‚¹**ã€‚
*   **æ—¥çº¿ (1D) - è¶‹åŠ¿ç¡®ç«‹ (æ»¡è¶³Aæˆ–B):**
    *   **A) å½¢æ€**: MACDä¿¡å·çº¿(æ…¢çº¿)åœ¨**5æ ¹Kçº¿å†…**ä»ä¸‹æ–¹ä¸Šç©¿0è½´ã€‚
    *   **B) æ–°é²œåº¦**: ä»·æ ¼è·ä¸Šæ¬¡â€œç©¿è½´ç‚¹â€çš„æ¶¨å¹… < **2å€ATR** (æ—¥çº¿)ã€‚
*   **æ—¥çº¿ (1D) - åŠ¨èƒ½ç¡®è®¤ (å¿…é¡»æ»¡è¶³):**
    *   å¤„äº**é‡‘å‰**çŠ¶æ€ ä¸” **MACDåŠ¨èƒ½æŸ±å¢å¼º** (Histogramå˜é•¿)ã€‚
*   **4å°æ—¶ (4H) - å‘¨æœŸå…±æŒ¯ (å¿…é¡»æ»¡è¶³):**
    *   åŒæ ·å¤„äº**é‡‘å‰**çŠ¶æ€ ä¸” **MACDåŠ¨èƒ½æŸ±å¢å¼º**ã€‚

#### **â¡ï¸ å¤šå¤´å»¶ç»­ (Long Continuation)**
*   **ç›®æ ‡**: åœ¨å·²ç¡®ç«‹çš„å¼ºåŠ¿ä¸Šæ¶¨è¶‹åŠ¿ä¸­ï¼Œæ•æ‰**ä¸­æœŸå›è°ƒç»“æŸåçš„ç¡®è®¤ç‚¹**ã€‚
*   **æ—¥çº¿ (1D) - å¼ºè¶‹åŠ¿èƒŒæ™¯:**
    *   MACDåŒçº¿(å¿«æ…¢çº¿)ç¨³å®šè¿è¡Œåœ¨**0è½´ä¹‹ä¸Š** (æœ€è¿‘5æ ¹Kçº¿ä¿¡å·çº¿æœªè·Œç ´0è½´)ã€‚
*   **4å°æ—¶ (4H) - ä¸­æœŸç»“æ„:**
    *   å½¢æˆ**â€œæ–°é²œçš„â€é‡‘å‰** (5æ ¹4H Kçº¿å†…å½¢æˆï¼Œä¸”ä»·æ ¼æ³¢åŠ¨ < 2å€ATR)ã€‚
*   **1å°æ—¶ (1H) - å…¥åœºè§¦å‘:**
    *   MACD**åˆšåˆšå½¢æˆé‡‘å‰** (å½“å‰Kçº¿æ˜¯é‡‘å‰ï¼Œä¸Šä¸€æ ¹è¿˜ä¸æ˜¯)ã€‚

#### **ğŸ‚ å¤šå¤´å›è°ƒ (Long Pullback)**
*   **ç›®æ ‡**: åœ¨å¼ºè¶‹åŠ¿ä¸­ï¼Œæ•æ‰**çŸ­æœŸå›è°ƒç»“æŸåçš„æœ€æ—©å…¥åœºç‚¹**ã€‚
*   **æ—¥çº¿ (1D) - å¼ºè¶‹åŠ¿èƒŒæ™¯:**
    *   åŒâ€œå¤šå¤´å»¶ç»­â€ï¼ŒMACDåŒçº¿ç¨³å®šåœ¨**0è½´ä¹‹ä¸Š**ã€‚
*   **4å°æ—¶ (4H) - å›è°ƒç»“æŸè¿¹è±¡:**
    *   MACDç©ºå¤´åŠ¨èƒ½æŸ±**æ­£åœ¨è¡°ç«­** (Histogramæ”¶ç¼©æˆ–ç¿»çº¢)ã€‚
*   **1å°æ—¶ (1H) - å…¥åœºè§¦å‘:**
    *   MACD**åˆšåˆšå½¢æˆé‡‘å‰** ä¸” **å¤šå¤´åŠ¨èƒ½æŸ±æ­£åœ¨å¢å¼º**ã€‚

#### **ğŸ”¥ å‡¤å‡°ä¿¡å· (Long Phoenix)**
*   **ç›®æ ‡**: åœ¨å·²ç¡®ç«‹çš„å¤šå¤´è¶‹åŠ¿ä¸­ï¼Œæ•æ‰ä¸€æ¬¡**â€œæ·±åº¦å›è°ƒâ€ç»“æŸåçš„é»„é‡‘å‘**æœºä¼šã€‚
*   **åŸºç¡€å‰æ**:
    *   é¦–å…ˆå¿…é¡»æ»¡è¶³â€œ**å¤šå¤´å»¶ç»­**â€æˆ–â€œ**å¤šå¤´å›è°ƒ**â€çš„æ‰€æœ‰æ¡ä»¶ã€‚
*   **æ ¸å¿ƒæ¡ä»¶ - æ·±åº¦å›æ’¤ (å¿…é¡»æ»¡è¶³):**
    *   ä»æœ¬è½®æ—¥çº¿è¶‹åŠ¿å¯åŠ¨åçš„æœ€é«˜ç‚¹ç®—èµ·ï¼Œå½“å‰ä»·æ ¼çš„**å›æ’¤å¹…åº¦ > 70%**ã€‚
*   **å¥åº·æ£€æŸ¥ (å¿…é¡»åŒæ—¶æ»¡è¶³):**
    *   **1) è¶‹åŠ¿æœ‰æ•ˆæ€§**: å‰æœŸä¸Šæ¶¨å¿…é¡»æœ‰åŠ›ï¼Œæœ€é«˜ç‚¹æ¶¨å¹… > **15%**ã€‚
    *   **2) æ³¢åŠ¨æ”¶ç¼©**: å›è°ƒæœ«ç«¯ï¼Œæ—¥çº¿å¸ƒæ—å¸¦å¸¦å®½å¤„äº**å†å²ä½ä½** (30%åˆ†ä½æ•°ä»¥ä¸‹)ã€‚

---
*æ³¨ï¼šæ‰€æœ‰ç©ºå¤´ä¿¡å· (ğŸ“‰å¯åŠ¨, â†˜ï¸å»¶ç»­, ğŸ»å›è°ƒ) çš„æ¡ä»¶ä¸å¯¹åº”çš„å¤šå¤´ä¿¡å·å®Œå…¨ç›¸åã€‚*
"""
    
    def format_volume(self, volume):
        if volume >= 1_000_000_000: return f"{volume/1_000_000_000:.2f}B"
        if volume >= 1_000_000: return f"{volume/1_000_000:.2f}M"
        if volume >= 1_000: return f"{volume/1_000:.2f}K"
        return f"{volume:.2f}"
    
    def get_market_sentiment(self, btc_data):
        klines = {
            '1D': self._parse_klines_to_df(btc_data['d1'])['close'],
            '4H': self._parse_klines_to_df(btc_data['h4'])['close'],
            '1H': self._parse_klines_to_df(btc_data['h1'])['close']
        }
        macds = {tf: self.calculate_macd(prices) for tf, prices in klines.items()}
        if any(m.empty for m in macds.values()): return {'sentiment': 'Neutral', 'text':"BTCæ•°æ®ä¸è¶³", 'details': ''}

        score, bull_points, bear_points = 0, [], []
        weights = {'1D': 2, '4H': 1, '1H': 0.5}

        for tf in ['1D', '4H', '1H']:
            last, prev = macds[tf].iloc[-1], macds[tf].iloc[-2]
            tf_text = f"**{tf}**:"
            if last['macd'] > 0 and last['signal'] > 0: score += 1 * weights[tf]; bull_points.append(f"{tf_text} åŒçº¿ä½äº0è½´ä¹‹ä¸Š")
            if last['macd'] < 0 and last['signal'] < 0: score -= 1 * weights[tf]; bear_points.append(f"{tf_text} åŒçº¿ä½äº0è½´ä¹‹ä¸‹")
            
            if last['macd'] > last['signal']:
                score += 0.5 * weights[tf]
                point = f"{tf_text} é‡‘å‰"
                if last['histogram'] > prev['histogram']: point += "ä¸”å¤šå¤´åŠ¨èƒ½å¢å¼º"
                else: point += "ä½†å¤šå¤´åŠ¨èƒ½å‡å¼±"
                bull_points.append(point)
            else:
                score -= 0.5 * weights[tf]
                point = f"{tf_text} æ­»å‰"
                if last['histogram'] < prev['histogram']: point += "ä¸”ç©ºå¤´åŠ¨èƒ½å¢å¼º"
                else: point += "ä½†ç©ºå¤´åŠ¨èƒ½å‡å¼±"
                bear_points.append(point)

        if score >= 3.5: sentiment, text = 'Bullish', "å¼ºåŠ¿çœ‹æ¶¨ ğŸ‚"
        elif score >= 1.5: sentiment, text = 'Bullish', "éœ‡è¡åå¤š ğŸ“ˆ"
        elif score <= -3.5: sentiment, text = 'Bearish', "å¼ºåŠ¿çœ‹ç©º ğŸ»"
        elif score <= -1.5: sentiment, text = 'Bearish', "éœ‡è¡åç©º ğŸ“‰"
        else: sentiment, text = 'Neutral', "å¤šç©ºèƒ¶ç€ íš¡ë³´"
        
        details = ""
        if bull_points:
            details += "#### ğŸ‚ çœ‹å¤šç†ç”±\n- " + "\n- ".join(bull_points)
        if bear_points:
            details += "\n\n#### ğŸ» çœ‹ç©ºç†ç”±\n- " + "\n- ".join(bear_points)

        return {'sentiment': sentiment, 'text': text, 'details': details.strip()}

    def load_watchlist_state(self):
        if not os.path.exists(self.state_file): return {}
        try:
            with open(self.state_file, 'r') as f: return json.load(f)
        except: return {}

    def save_watchlist_state(self, watchlist):
        try:
            with open(self.state_file, 'w') as f: json.dump(watchlist, f)
        except Exception as e: print(f"ä¿å­˜çŠ¶æ€æ–‡ä»¶å¤±è´¥: {e}")

    # --- Backtesting and Reporting ---
    def analyze_signal_performance(self, signal):
        now = time.time() * 1000
        time_since_signal_ms = now - signal['signalTime']
        minutes_since_signal = time_since_signal_ms / (1000 * 60)
        
        candles_to_fetch = min(300, int(minutes_since_signal / 5) + 2)
        if candles_to_fetch <= 1:
            return {'maxMovePct': 0, 'timeToPeak': '0m'}

        klines_5m_raw = self.get_kline_data(signal['inst_id'], '5m', candles_to_fetch)
        if not klines_5m_raw:
            return {'maxMovePct': None, 'timeToPeak': 'N/A'}

        klines_5m_df = self._parse_klines_to_df(klines_5m_raw)
        relevant_klines = klines_5m_df[klines_5m_df['ts'] > signal['signalTime']]

        if relevant_klines.empty:
            return {'maxMovePct': 0, 'timeToPeak': '0m'}

        peak_price, peak_time = 0, 0
        if 'Long' in signal['type']:
            if relevant_klines['high'].empty: return {'maxMovePct': 0, 'timeToPeak': '0m'}
            peak_price = relevant_klines['high'].max()
            peak_candle = relevant_klines.loc[relevant_klines['high'].idxmax()]
            peak_time = peak_candle['ts']
        else: # Short
            if relevant_klines['low'].empty: return {'maxMovePct': 0, 'timeToPeak': '0m'}
            peak_price = relevant_klines['low'].min()
            peak_candle = relevant_klines.loc[relevant_klines['low'].idxmin()]
            peak_time = peak_candle['ts']
            
        max_move_pct = ((peak_price - signal['signalPrice']) / signal['signalPrice']) * 100
        time_to_peak_mins = round((peak_time - signal['signalTime']) / (1000 * 60))

        return {'maxMovePct': max_move_pct, 'timeToPeak': f"{time_to_peak_mins}m"}

    def create_backtest_report(self, historical_signals):
        if not historical_signals:
            return "### ğŸ“Š è¿‡å»12å°æ—¶ä¿¡å·å›æµ‹ ğŸ“Š\n\nåœ¨è¿‡å»12å°æ—¶å†…æœªå‘ç°ç¬¦åˆç­–ç•¥çš„äº¤æ˜“ä¿¡å·ã€‚\n"

        report = "### ğŸ“Š è¿‡å»12å°æ—¶ä¿¡å·å›æµ‹ ğŸ“Š\n"
        type_map = { 'Long Trend': 'ğŸš€ å¤šå¤´å¯åŠ¨', 'Long Phoenix': 'ğŸ”¥ å‡¤å‡°ä¿¡å·', 'Long Continuation': 'â¡ï¸ å¤šå¤´å»¶ç»­', 'Long Pullback': 'ğŸ‚ å¤šå¤´å›è°ƒ', 'Short Trend': 'ğŸ“‰ ç©ºå¤´å¯åŠ¨', 'Short Continuation': 'â†˜ï¸ ç©ºå¤´å»¶ç»­', 'Short Pullback': 'ğŸ» ç©ºå¤´å›è°ƒ' }
        grouped_signals = {}
        for sig in historical_signals:
            inst_name = sig['inst_id'].replace('-USDT-SWAP', '')
            if inst_name not in grouped_signals:
                grouped_signals[inst_name] = []
            grouped_signals[inst_name].append(sig)

        sorted_groups = sorted(grouped_signals.items(), key=lambda item: max(s['signalTime'] for s in item[1]), reverse=True)

        for inst_name, signals in sorted_groups:
            report += f"\n#### **{inst_name}** ({len(signals)}æ¡ä¿¡å·)\n"
            report += "| æœ‰æ•ˆæ€§ | é¢†è¢–åˆ† | è´¨é‡åˆ† | ä¿¡å·æ—¶é—´ | ç±»å‹ | RSåˆ† | ä¿¡å·ä»· | æœ€å¤§æ¶¨/è·Œå¹… | è¾¾å³°è€—æ—¶ |\n"
            report += "|:---:|:---:|:---:|:---|:---|:---:|:---:|:---:|:---:|\n"
            
            signals.sort(key=lambda x: x['signalTime'], reverse=True)
            
            for sig in signals:
                perf = sig.get('performance', {})
                max_move = perf.get('maxMovePct')
                is_effective = "N/A"
                if max_move is not None:
                    if 'Long' in sig['type'] and max_move > 0.2: is_effective = "âœ… æœ‰æ•ˆ"
                    elif 'Short' in sig['type'] and max_move < -0.2: is_effective = "âœ… æœ‰æ•ˆ"
                    else: is_effective = "âŒ æ— æ•ˆ"
                
                move_str = "æŸ¥è¯¢å¤±è´¥"
                if max_move is not None:
                    move_str = f"ğŸ“ˆ {max_move:.2f}%" if max_move > 0 else f"ğŸ“‰ {max_move:.2f}%"

                sig_time = datetime.fromtimestamp(sig['signalTime']/1000, self.timezone).strftime('%H:%M')
                time_ago = f"({sig['hoursAgo']}Hå‰)"
                
                leader_score = sig.get('leader_score') if sig.get('leader_score') is not None else 'N/A'
                quality_score = sig.get('quality_score') if sig.get('quality_score') is not None else 'N/A'
                rs_score = sig.get('rs_score') if sig.get('rs_score') is not None else 'N/A'

                report += f"| {is_effective} | {leader_score} | {quality_score} | {sig_time} {time_ago} | {type_map.get(sig['type'], sig['type'])} | {rs_score} | {sig['signalPrice']:.4g} | {move_str} | {perf.get('timeToPeak', 'N/A')} |\n"
                
        return report
        
    def create_debug_report(self):
        if not self.debug_logs:
            return ""

        report = "\n---\n### **ç­–ç•¥è°ƒè¯•æ—¥å¿—**\n"
        
        # Sort by leader score, descending. Handle None values.
        self.debug_logs.sort(key=lambda x: x.get('leader_score') or -1, reverse=True)
        
        type_map = {'Long Trend': 'ğŸš€', 'Long Phoenix': 'ğŸ”¥', 'Long Continuation': 'â¡ï¸', 'Long Pullback': 'ğŸ‚', 'Short Trend': 'ğŸ“‰', 'Short Continuation': 'â†˜ï¸', 'Short Pullback': 'ğŸ»'}

        report += "| äº¤æ˜“å¯¹ | é¢†è¢–åˆ† | RSåˆ† | å¯åŠ¨ | å»¶ç»­/å›è°ƒ | å‡¤å‡° | è¯¦æƒ… |\n"
        report += "|:---|:---:|:---:|:---:|:---:|:---:|:---:|\n"

        for log in self.debug_logs:
            inst_name = log['inst_id'].replace('-USDT-SWAP', '')
            leader_score = log.get('leader_score')
            leader_str = f"{leader_score}" if leader_score is not None else 'N/A'
            rs_score = log.get('rs_score')
            rs_str = f"{rs_score}" if rs_score is not None else 'N/A'

            trend_res = log['checks'].get('å¤šå¤´å¯åŠ¨', {}).get('final_result') or log['checks'].get('ç©ºå¤´å¯åŠ¨', {}).get('final_result')
            trend_icon = type_map.get(trend_res, 'â–')

            cont_res = log['checks'].get('é¡ºåŠ¿å¤šå¤´', {}).get('final_result') or log['checks'].get('é¡ºåŠ¿ç©ºå¤´', {}).get('final_result')
            cont_icon = type_map.get(cont_res, 'â–')
            
            phoenix_res = log['checks'].get('å‡¤å‡°ä¿¡å·', {}).get('final_result')
            phoenix_icon = type_map.get(phoenix_res, 'â–')

            details = ""
            for category, data in log['checks'].items():
                details += f"**{category}**:<br>"
                for step in data['steps']:
                    details += f"&nbsp;&nbsp;- {step['name']}: {step['val']} -> {step['res']}<br>"
            
            report += f"| **{inst_name}** | {leader_str} | {rs_str} | {trend_icon} | {cont_icon} | {phoenix_icon} | <details><summary>æŸ¥çœ‹</summary>{details}</details> |\n"

        return report

    def create_opportunity_report(self, backtest_report, opportunities, market_info, upgraded_signals, debug_report):
        opportunities.sort(key=lambda x: x.get('leader_score', 0) or 0, reverse=True)
        upgraded_signals.sort(key=lambda x: x.get('leader_score', 0) or 0, reverse=True)
        type_map = { 'Long Trend': 'ğŸš€ å¤šå¤´å¯åŠ¨', 'Long Phoenix': 'ğŸ”¥ å‡¤å‡°ä¿¡å·', 'Long Continuation': 'â¡ï¸ å¤šå¤´å»¶ç»­', 'Long Pullback': 'ğŸ‚ å¤šå¤´å›è°ƒ', 'Long Watchlist': 'ğŸ‘€ å¤šå¤´è§‚å¯Ÿ', 'Short Trend': 'ğŸ“‰ ç©ºå¤´å¯åŠ¨', 'Short Continuation': 'â†˜ï¸ ç©ºå¤´å»¶ç»­', 'Short Pullback': 'ğŸ» ç©ºå¤´å›è°ƒ', 'Short Watchlist': 'ğŸ‘€ ç©ºå¤´è§‚å¯Ÿ' }
        
        content = f"{backtest_report}\n---\n"
        content += f"### ğŸ”¥ å½“å‰æœ€æ–°æœºä¼šä¿¡å· (ä»…æ˜¾ç¤ºRS > 80)\n"
        content += f"**å¸‚åœºæƒ…ç»ª: {market_info.get('text', 'N/A')}**\n\n{market_info.get('details', '')}\n"

        def generate_table(title, opp_list):
            if not opp_list: return ""
            table = f"### {title}\n"
            table += "| é¢†è¢–åˆ† | è´¨é‡åˆ† | RSåˆ† | äº¤æ˜“å¯¹ | æœºä¼šç±»å‹ | è¶‹åŠ¿å¹…åº¦ | è¶‹åŠ¿æ—¶é•¿ | 24Hæˆäº¤é¢ | 24Hæ¶¨è·Œå¹… |\n"
            table += "|:---:|:---:|:---:|:---|:---|:---:|:---:|:---:|:---:|\n"
            for opp in opp_list:
                inst_name = opp['inst_id'].replace('-USDT-SWAP', '')
                opp_type = type_map.get(opp['type'], 'æœªçŸ¥')
                vol_str = self.format_volume(opp['volume'])
                change_24h = opp.get('price_change_24h', 0)
                change_24h_str = f"ğŸ“ˆ {change_24h:.2f}%" if change_24h > 0 else f"ğŸ“‰ {change_24h:.2f}%"
                
                leader_score_val = opp.get('leader_score')
                leader_score = f"**{leader_score_val}**" if leader_score_val is not None and leader_score_val >= 80 else str(leader_score_val if leader_score_val is not None else 'N/A')
                
                quality_score_val = opp.get('quality_score')
                quality_score = f"**{quality_score_val}**" if quality_score_val is not None and quality_score_val >= 80 else str(quality_score_val if quality_score_val is not None else 'N/A')

                rs_score_val = opp.get('rs_score')
                rs_score = f"**{rs_score_val}**" if rs_score_val is not None and rs_score_val >= 80 else str(rs_score_val if rs_score_val is not None else 'N/A')
                
                trend_change = opp.get('trend_change_pct', 0)
                trend_change_str = f"ğŸ“ˆ {trend_change:.1f}%" if trend_change > 0 else (f"ğŸ“‰ {trend_change:.1f}%" if trend_change < 0 else "N/A")
                trend_days = opp.get('trend_duration_days', 0)
                trend_days_str = f"{trend_days:.1f}å¤©" if trend_days > 0 else "N/A"
                warning = " (é€†å¤§ç›˜)" if (market_info['sentiment'] == 'Bullish' and 'Short' in opp['type']) or \
                                      (market_info['sentiment'] == 'Bearish' and 'Long' in opp['type']) else ""
                table += f"| {leader_score} | {quality_score} | {rs_score} | **{inst_name}** | {opp_type}{warning} | {trend_change_str} | {trend_days_str} | {vol_str} | {change_24h_str} |\n"
            return table

        upgraded_ids = {s['inst_id'] for s in upgraded_signals}
        new_actionable = [opp for opp in opportunities if opp['inst_id'] not in upgraded_ids]
        
        # Only add tables if there is content for them after filtering
        if upgraded_signals:
            content += generate_table('âœ¨ ä¿¡å·å‡çº§ âœ¨ (RS > 80)', upgraded_signals)
        if new_actionable:
            content += generate_table('ğŸ’ æ–°æœºä¼šä¿¡å· (RS > 80)', new_actionable)
        
        if not upgraded_signals and not new_actionable:
            content += "\nåœ¨å½“å‰æ—¶é—´ç‚¹ï¼Œæœªå‘ç°RSè¯„åˆ†é«˜äº80çš„å®æ—¶äº¤æ˜“æœºä¼šã€‚\n"

        content += self.get_strategy_explanation()
        content += debug_report # Append the debug log at the end
        return content

    def _get_historical_snapshot(self, i, full_data_df, btc_full_df, eth_full_df):
        if len(full_data_df['h1']) <= i: return None
        h1_snapshot_df = full_data_df['h1'].iloc[:-i]
        last_h1_candle_ts = h1_snapshot_df['ts'].iloc[-1]
        
        h4_snapshot_df = full_data_df['h4'][full_data_df['h4']['ts'] <= last_h1_candle_ts]
        d1_snapshot_df = full_data_df['d1'][full_data_df['d1']['ts'] <= last_h1_candle_ts]
        btc_d1_snapshot_df = btc_full_df['d1'][btc_full_df['d1']['ts'] <= last_h1_candle_ts]
        eth_d1_snapshot_df = eth_full_df['d1'][eth_full_df['d1']['ts'] <= last_h1_candle_ts]

        if h1_snapshot_df.empty or h4_snapshot_df.empty or d1_snapshot_df.empty or btc_d1_snapshot_df.empty or eth_d1_snapshot_df.empty:
            return None

        return {
            'h1': h1_snapshot_df.to_dict('records'),
            'h4': h4_snapshot_df.to_dict('records'),
            'd1': d1_snapshot_df.to_dict('records'),
            'btc': {'d1': btc_d1_snapshot_df.to_dict('records')},
            'eth': {'d1': eth_d1_snapshot_df.to_dict('records')}
        }

    def run_backtest(self, all_instruments_data):
        print(f"[{self.get_current_time_str()}] === å¼€å§‹æ‰§è¡Œ12å°æ—¶ä¿¡å·å›æµ‹ ===")
        historical_signals = []
        unique_signal_checker = set()
        
        btc_full_history = all_instruments_data.get('BTC-USDT-SWAP')
        eth_full_history = all_instruments_data.get('ETH-USDT-SWAP')
        if not btc_full_history or not eth_full_history:
            print("BTCæˆ–ETHæ•°æ®ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œå›æµ‹ã€‚")
            return ""

        all_instruments_df = {
            inst: {
                'h1': self._parse_klines_to_df(data['h1']),
                'h4': self._parse_klines_to_df(data['h4']),
                'd1': self._parse_klines_to_df(data['d1'])
            } for inst, data in all_instruments_data.items()
        }
        btc_full_df = all_instruments_df.get('BTC-USDT-SWAP')
        eth_full_df = all_instruments_df.get('ETH-USDT-SWAP')

        for i in range(1, 13):
            print(f"\ræ­£åœ¨å›æº¯è¿‡å»ç¬¬ {i}/12 å°æ—¶çš„ä¿¡å·...", end="")
            for inst_id, data_df in all_instruments_df.items():
                
                historical_snapshot = self._get_historical_snapshot(i, data_df, btc_full_df, eth_full_df)
                if not historical_snapshot: continue
                
                signal = self.analyze_instrument(inst_id, historical_snapshot, is_historical=True)

                if signal and 'Watchlist' not in signal['type']:
                    unique_id = f"{signal['inst_id']}-{signal['type']}-{signal['signalTime']}"
                    if unique_id not in unique_signal_checker:
                        signal['hoursAgo'] = i
                        historical_signals.append(signal)
                        unique_signal_checker.add(unique_id)
        
        print(f"\n[{self.get_current_time_str()}] å›æµ‹å®Œæˆï¼Œå‘ç° {len(historical_signals)} ä¸ªå†å²ä¿¡å·ã€‚")

        if historical_signals:
            print(f"[{self.get_current_time_str()}] æ­£åœ¨å¹¶å‘åˆ†æ {len(historical_signals)} ä¸ªå†å²ä¿¡å·çš„è¡¨ç°...")
            with ThreadPoolExecutor(max_workers=self.STRICT_CONCURRENCY_LIMIT) as executor:
                future_to_signal = {executor.submit(self.analyze_signal_performance, sig): sig for sig in historical_signals}
                for j, future in enumerate(as_completed(future_to_signal)):
                    signal = future_to_signal[future]
                    try:
                        performance_data = future.result()
                        signal['performance'] = performance_data
                        print(f"\rä¿¡å·è¡¨ç°åˆ†æè¿›åº¦: {j+1}/{len(historical_signals)}", end="")
                    except Exception as exc:
                        print(f'{signal["inst_id"]} ç”Ÿæˆè¡¨ç°æ—¶å‡ºé”™: {exc}')
            print(f"\n[{self.get_current_time_str()}] å†å²ä¿¡å·è¡¨ç°åˆ†æå®Œæˆã€‚")

        return self.create_backtest_report(historical_signals)

    # --- ä¸»è¿è¡Œå‡½æ•° ---
    def run(self):
        start_time = time.time()
        print(f"[{self.get_current_time_str()}] === å¼€å§‹æ‰§è¡Œç›‘æ§ä»»åŠ¡ ===")
        
        self.debug_logs = [] # é‡ç½®è°ƒè¯•æ—¥å¿—
        previous_watchlist = self.load_watchlist_state()
        instruments = self.get_perpetual_instruments()
        if not instruments: return
        
        print(f"[{self.get_current_time_str()}] æ­£åœ¨å¹¶å‘è·å– {len(instruments)} ä¸ªå¸ç§çš„Kçº¿æ•°æ®...")
        all_instruments_data = {}
        with ThreadPoolExecutor(max_workers=self.CONCURRENCY_LIMIT) as executor:
            futures = [executor.submit(self.fetch_all_data_for_instrument, inst) for inst in instruments]
            for i, future in enumerate(as_completed(futures)):
                inst_id, data = future.result()
                if data:
                    all_instruments_data[inst_id] = data
                print(f"\ræ•°æ®è·å–è¿›åº¦: {i+1}/{len(instruments)}", end="")
        print(f"\n[{self.get_current_time_str()}] æ•°æ®è·å–å®Œæ¯•ï¼Œè€—æ—¶ {time.time() - start_time:.2f}ç§’. æœ‰æ•ˆæ•°æ®: {len(all_instruments_data)}ä¸ªå¸ç§ã€‚")

        backtest_report = self.run_backtest(all_instruments_data)
        
        print(f"[{self.get_current_time_str()}] === å¼€å§‹æ‰§è¡Œå½“å‰ä¿¡å·æ‰«æ ===")
        btc_data = all_instruments_data.get('BTC-USDT-SWAP')
        if not btc_data:
            print("æœªèƒ½è·å–BTCæ•°æ®ï¼Œä»»åŠ¡ç»ˆæ­¢ã€‚")
            return
            
        market_info = self.get_market_sentiment(btc_data)
        print(f"[{self.get_current_time_str()}] å½“å‰å¸‚åœºæƒ…ç»ª: {market_info['text']}")
        
        all_opportunities = []
        with ThreadPoolExecutor(max_workers=os.cpu_count() or 4) as executor:
            current_snapshots = {}
            btc_full, eth_full = all_instruments_data['BTC-USDT-SWAP'], all_instruments_data['ETH-USDT-SWAP']
            for inst_id, data in all_instruments_data.items():
                current_snapshots[inst_id] = {**data, 'btc': btc_full, 'eth': eth_full}

            futures = [executor.submit(self.analyze_instrument, inst_id, snap, is_historical=False) for inst_id, snap in current_snapshots.items()]
            for i, future in enumerate(as_completed(futures)):
                result = future.result()
                if result:
                    all_opportunities.append(result)
        print(f"\n[{self.get_current_time_str()}] ä¿¡å·åˆ†æå®Œæ¯•ï¼Œå‘ç° {len(all_opportunities)} ä¸ªæ½œåœ¨ä¿¡å·ã€‚")

        actionable_opportunities = []
        upgraded_signals = []
        new_watchlist = {}

        if all_opportunities:
            print(f"[{self.get_current_time_str()}] æ­£åœ¨è·å– {len(all_opportunities)} ä¸ªä¿¡å·å¸ç§çš„24Hæ¶¨è·Œå¹…...")
            with ThreadPoolExecutor(max_workers=self.CONCURRENCY_LIMIT) as executor:
                ticker_futures = {executor.submit(self.get_ticker_data, opp['inst_id']): opp for opp in all_opportunities}
                for future in as_completed(ticker_futures):
                    opp = ticker_futures[future]
                    ticker_data = future.result()
                    opp['price_change_24h'] = ticker_data.get('price_change_24h', 0)

            for opp in all_opportunities:
                inst_id, opp_type = opp['inst_id'], opp['type']
                if 'Watchlist' not in opp_type:
                    actionable_opportunities.append(opp)
                    if inst_id in previous_watchlist:
                        upgraded_signals.append(opp)
                        print(f"[{self.get_current_time_str()}] âœ¨ ä¿¡å·å‡çº§: {inst_id} ä» {previous_watchlist[inst_id]} å‡çº§ä¸º {opp_type}")
                if 'Watchlist' in opp_type:
                    new_watchlist[inst_id] = opp_type
        
        self.save_watchlist_state(new_watchlist)
        
        # --- NEW: Filter signals based on RS Score > 80 ---
        initial_actionable_count = len(actionable_opportunities)
        actionable_opportunities_filtered = [
            opp for opp in actionable_opportunities 
            if opp.get('rs_score') is not None and opp.get('rs_score') > 80
        ]
        upgraded_signals_filtered = [
            opp for opp in upgraded_signals 
            if opp.get('rs_score') is not None and opp.get('rs_score') > 80
        ]
        print(f"[{self.get_current_time_str()}] åˆå§‹å‘ç° {initial_actionable_count} ä¸ªå¯æ“ä½œä¿¡å·, ç»è¿‡RS > 80ç­›é€‰åå‰©ä½™ {len(actionable_opportunities_filtered)} ä¸ªã€‚")

        # --- Generate final reports ---
        debug_report = self.create_debug_report()

        # Decide whether to send a notification
        if actionable_opportunities_filtered:
            title = ""
            new_actionable_count = len(actionable_opportunities_filtered) - len(upgraded_signals_filtered)
            if upgraded_signals_filtered:
                title += f"âœ¨ {len(upgraded_signals_filtered)}ä¸ªå‡çº§(RS>80)"
                if new_actionable_count > 0:
                    title += f" + {new_actionable_count}ä¸ªæ–°æœºä¼š"
            else:
                title = f"ğŸ’ å‘ç° {len(actionable_opportunities_filtered)} ä¸ªæ–°æœºä¼š(RS>80)"
            
            content = self.create_opportunity_report(
                backtest_report, 
                actionable_opportunities_filtered, 
                market_info, 
                upgraded_signals_filtered,
                debug_report
            )
            self.send_notification(title, content)
        else:
            print(f"[{self.get_current_time_str()}] æœªå‘ç°RS > 80çš„å®æ—¶ä¿¡å·ã€‚")
            if "æœªå‘ç°" not in backtest_report:
                # If there are no live signals but there is a backtest result, send it
                content = self.create_opportunity_report(backtest_report, [], market_info, [], debug_report)
                self.send_notification("OKX 12å°æ—¶ç­–ç•¥å›æµ‹æŠ¥å‘Š", content)

        end_time = time.time()
        print(f"[{self.get_current_time_str()}] === ç›‘æ§ä»»åŠ¡æ‰§è¡Œå®Œæ¯•ï¼Œæ€»è€—æ—¶: {end_time - start_time:.2f}ç§’ ===")

if __name__ == "__main__":
    monitor = OKXMonitor()
    monitor.run()
