#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import requests
import json
import time
import os
from datetime import datetime, timedelta
import pandas as pd
import numpy as np
import pytz
from concurrent.futures import ThreadPoolExecutor, as_completed
from math import floor

class OKXMonitor:
    def __init__(self):
        # --- æ ¸å¿ƒé…ç½® ---
        self.base_url = "https://www.okx.com"
        self.server_jiang_key = 'SCT281228TBF1BQU3KUJ4vLRkykhzIE80e'
        
        # --- ç­–ç•¥å‚æ•° ---
        self.MACD_VOLUME_THRESHOLD = 10_000_000
        self.ATR_MULTIPLIER = 2.0
        self.MAX_CANDLES_AGO = 5
        
        # --- ç³»ç»Ÿé…ç½® ---
        self.session = self._create_session()
        self.timezone = pytz.timezone('Asia/Shanghai')
        self.state_file = 'watchlist_state.json'
        self.CONCURRENCY_LIMIT = 10
        self.STRICT_CONCURRENCY_LIMIT = 5 # For bursty requests like performance analysis
        self.request_timestamps = []
        self.RATE_LIMIT_COUNT = 18
        self.RATE_LIMIT_WINDOW = 2000

    # ... [The utility, data fetching, and indicator calculation methods from the previous version remain unchanged] ...
    # ... [__init__, _create_session, get_current_time_str, _rate_limiter, fetch_with_retry, send_notification] ...
    # ... [get_perpetual_instruments, get_kline_data, get_ticker_data] ...
    # ... [_parse_klines_to_df, calculate_macd, calculate_atr, calculate_bollinger_bands, _get_change] ...
    # ... [All scoring functions: calculate_rs_score, calculate_market_leadership_score, etc.] ...
    # ... [Signal helper functions: find_last_cross_info, etc.] ...
    
    def _create_session(self):
        session = requests.Session()
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept-Language': 'en-US,en;q=0.9',
        }
        session.headers.update(headers)
        return session
    
    def get_current_time_str(self):
        return datetime.now(self.timezone).strftime('%Y-%m-%d %H:%M:%S')

    def _rate_limiter(self):
        now = int(time.time() * 1000)
        self.request_timestamps = [ts for ts in self.request_timestamps if now - ts < self.RATE_LIMIT_WINDOW]
        if len(self.request_timestamps) >= self.RATE_LIMIT_COUNT:
            oldest_request_time = self.request_timestamps[0]
            time_passed = now - oldest_request_time
            delay = (self.RATE_LIMIT_WINDOW - time_passed) / 1000
            if delay > 0:
                time.sleep(delay + 0.05)
        self.request_timestamps.append(int(time.time() * 1000))

    def fetch_with_retry(self, url, params, retries=5, timeout=15):
        self._rate_limiter()
        for i in range(retries):
            try:
                response = self.session.get(url, params=params, timeout=timeout)
                if response.status_code == 429:
                    raise Exception(f"è¯·æ±‚é¢‘ç‡è¿‡é«˜ (429)")
                response.raise_for_status()
                data = response.json()
                if data.get('code') == '0':
                    return data.get('data')
                raise Exception(f"APIè¿”å›é”™è¯¯: {data.get('msg', 'æœªçŸ¥é”™è¯¯')}")
            except Exception as e:
                if i == retries - 1:
                    return None
                delay = 2**i + np.random.rand()
                time.sleep(delay)
        return None

    def send_notification(self, title, content):
        if not self.server_jiang_key:
            print(f"[{self.get_current_time_str()}] æœªé…ç½®SERVER_JIANG_KEYï¼Œé€šçŸ¥å°†æ‰“å°åˆ°æ§åˆ¶å°ã€‚")
            print(f"æ ‡é¢˜: {title}\nå†…å®¹:\n{content}")
            return
        desp = content
        try:
            url = f"https://sctapi.ftqq.com/{self.server_jiang_key}.send"
            data = {'title': title, 'desp': desp}
            response = requests.post(url, data=data, timeout=30)
            response.raise_for_status()
            result = response.json()
            if result.get('code') == 0:
                print(f"[{self.get_current_time_str()}] é€šçŸ¥å‘é€æˆåŠŸ: {title}")
            else:
                print(f"[{self.get_current_time_str()}] é€šçŸ¥å‘é€å¤±è´¥: {result}")
        except Exception as e:
            print(f"[{self.get_current_time_str()}] å‘é€é€šçŸ¥æ—¶å‡ºé”™: {e}")
    
    def get_perpetual_instruments(self):
        data = self.fetch_with_retry(f"{self.base_url}/api/v5/public/instruments", {'instType': 'SWAP'})
        if data:
            instruments = [inst['instId'] for inst in data if inst['state'] == 'live' and inst['instId'].endswith('-USDT-SWAP')]
            print(f"[{self.get_current_time_str()}] è·å–åˆ° {len(instruments)} ä¸ªæ´»è·ƒçš„USDTæ°¸ç»­åˆçº¦")
            return instruments
        print(f"[{self.get_current_time_str()}] è·å–äº¤æ˜“å¯¹å¤±è´¥ã€‚")
        return []

    def get_kline_data(self, inst_id, bar='1H', limit=100):
        data = self.fetch_with_retry(f"{self.base_url}/api/v5/market/candles", {'instId': inst_id, 'bar': bar, 'limit': limit})
        return data[::-1] if data else []

    def get_ticker_data(self, inst_id):
        data = self.fetch_with_retry(f"{self.base_url}/api/v5/market/ticker", {'instId': inst_id})
        if data and data[0]:
            ticker = data[0]
            last_price = float(ticker.get('last', 0))
            open_24h = float(ticker.get('open24h', 0))
            if open_24h > 0:
                return {'price_change_24h': ((last_price - open_24h) / open_24h) * 100}
        return {'price_change_24h': 0}

    def fetch_all_data_for_instrument(self, inst_id):
        with ThreadPoolExecutor(max_workers=3) as executor:
            future_h1 = executor.submit(self.get_kline_data, inst_id, '1H', 112 + 12) # Fetch extra for backtesting
            future_h4 = executor.submit(self.get_kline_data, inst_id, '4H', 105 + 4)
            future_d1 = executor.submit(self.get_kline_data, inst_id, '1D', 102 + 1)
            h1, h4, d1 = future_h1.result(), future_h4.result(), future_d1.result()
        if h1 and h4 and d1:
            return inst_id, {'h1': h1, 'h4': h4, 'd1': d1}
        return inst_id, None

    def _parse_klines_to_df(self, klines):
        if not klines: return pd.DataFrame()
        df = pd.DataFrame(klines, columns=['ts', 'open', 'high', 'low', 'close', 'vol', 'volCcy', 'volCcyQuote', 'confirm'])
        for col in df.columns:
            df[col] = pd.to_numeric(df[col])
        return df

    def calculate_macd(self, prices_series, fast=12, slow=26, signal=9):
        if len(prices_series) < slow: return pd.DataFrame()
        ema_fast = prices_series.ewm(span=fast, adjust=False).mean()
        ema_slow = prices_series.ewm(span=slow, adjust=False).mean()
        macd_line = ema_fast - ema_slow
        signal_line = macd_line.ewm(span=signal, adjust=False).mean()
        histogram = macd_line - signal_line
        return pd.DataFrame({'macd': macd_line, 'signal': signal_line, 'histogram': histogram})

    def calculate_atr(self, df, period=14):
        if df.empty or len(df) < period + 1: return pd.Series(dtype=float)
        high_low = df['high'] - df['low']
        high_close = (df['high'] - df['close'].shift()).abs()
        low_close = (df['low'] - df['close'].shift()).abs()
        tr = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)
        return tr.ewm(span=period, adjust=False).mean()
    
    def calculate_bollinger_bands(self, df, period=20, std_dev=2):
        if len(df) < period: return {}
        sma = df['close'].rolling(window=period).mean().iloc[-1]
        std = df['close'].rolling(window=period).std().iloc[-1]
        upper = sma + (std * std_dev)
        lower = sma - (std * std_dev)
        bandwidth = (upper - lower) / sma if sma > 0 else 0
        return {'upper': upper, 'lower': lower, 'bandwidth': bandwidth}

    def _get_change(self, df, period):
        if df is not None and len(df) > period:
            latest_close = df['close'].iloc[-1]
            past_close = df['close'].iloc[-1 - period]
            if past_close > 0:
                return ((latest_close - past_close) / past_close) * 100
        return None

    def calculate_rs_score(self, inst_df, btc_df, eth_df):
        periods = [5, 10, 20]
        excess_performances = []
        for period in periods:
            inst_change = self._get_change(inst_df, period)
            btc_change = self._get_change(btc_df, period)
            eth_change = self._get_change(eth_df, period)
            if inst_change is None or btc_change is None or eth_change is None:
                return None
            benchmark_change = max(btc_change, eth_change)
            excess_performances.append(inst_change - benchmark_change)
        
        weighted_excess = (excess_performances[0] * 3 + excess_performances[1] * 2 + excess_performances[2] * 1) / 6
        raw_score = 50 + weighted_excess * 2.5
        return max(0, min(100, round(raw_score)))

    def calculate_market_leadership_score(self, inst_df, btc_df, eth_df):
        if len(inst_df) < 60: return None
        weights = {'rs': 40, 'resilience': 30, 'capital_flow': 20, 'trend_quality': 10}
        rs_score = self.calculate_rs_score(inst_df, btc_df, eth_df) or 0
        rs_component = rs_score * (weights['rs'] / 100)
        inst_returns = inst_df['close'].pct_change().iloc[1:]
        btc_returns = btc_df['close'].pct_change().iloc[1:]
        down_day_returns = inst_returns[btc_returns < -0.02]
        resilience_score = 50
        if not down_day_returns.empty:
            avg_inst_return_on_down_days = down_day_returns.mean()
            resilience_score = 50 + (avg_inst_return_on_down_days * 1000)
        resilience_component = max(0, min(100, resilience_score)) * (weights['resilience'] / 100)
        obv = (np.sign(inst_df['close'].diff()) * inst_df['vol']).fillna(0).cumsum()
        obv_sma20 = obv.rolling(20).mean().iloc[-1]
        obv_sma50 = obv.rolling(50).mean().iloc[-1]
        obv_score = 100 if obv_sma20 > obv_sma50 else 0
        vol_sma20 = inst_df['vol'].rolling(20).mean().iloc[-1]
        vol_sma50 = inst_df['vol'].rolling(50).mean().iloc[-1]
        vol_score = 100 if vol_sma20 > vol_sma50 else 0
        capital_flow_component = ((obv_score + vol_score) / 2) * (weights['capital_flow'] / 100)
        daily_returns = inst_df['close'].pct_change().dropna()
        std_dev = daily_returns.std()
        volatility_score = max(0, 100 - (std_dev * 2000))
        peak = inst_df['close'].expanding(min_periods=1).max()
        drawdown = (inst_df['close'] - peak) / peak
        max_drawdown = drawdown.min()
        drawdown_score = max(0, 100 - (abs(max_drawdown) * 200))
        trend_quality_component = ((volatility_score + drawdown_score) / 2) * (weights['trend_quality'] / 100)
        total_score = rs_component + resilience_component + capital_flow_component + trend_quality_component
        return max(0, min(100, round(total_score)))

    def calculate_startup_quality_score(self, opp, metrics):
        score = 0
        weights = {'volume': 30, 'momentum': 25, 'relativeStrength': 15, 'maDistance': 15, 'confirmation': 10, 'volatility': 5}
        vol_ratio = metrics['volume'] / metrics['avg_volume'] if metrics['avg_volume'] > 0 else 1
        vol_score = max(0, min(100, (vol_ratio - 1) * 50))
        growth_rate = (metrics['d1_hist'] - metrics['d1_prev_hist']) / abs(metrics['d1_prev_hist']) if metrics['d1_prev_hist'] != 0 else 0
        momentum_score = max(0, min(100, abs(growth_rate) * 100))
        rs_score_val = opp.get('rs_score', 50)
        ma_dist = (metrics['price'] - metrics['ema60']) / metrics['price'] if metrics['ema60'] else 0
        ma_score = max(0, (1 - abs(ma_dist) * 5) * 100)
        conf_score = min(100, (abs(metrics['h4_hist']) / metrics['price']) * 20000)
        volatility_score = max(0, (1 - metrics['bandwidth']) * 200)
        score += vol_score * weights['volume']
        score += momentum_score * weights['momentum']
        score += rs_score_val * weights['relativeStrength']
        score += ma_score * weights['maDistance']
        score += conf_score * weights['confirmation']
        score += volatility_score * weights['volatility']
        return round(score / 100)

    def calculate_continuation_quality_score(self, opp, d1_df, h4_df, d1_macd, h4_macd):
        weights = {'rs': 40, 'trendHealth': 25, 'volume': 25, 'volatility': 10}
        rs_component = (opp.get('rs_score', 0)) * (weights['rs'] / 100)
        price = d1_df['close'].iloc[-1]
        macd_pos_score = min(100, (abs(d1_macd['signal'].iloc[-1]) / price) * 3000)
        duration_score = min(100, (opp.get('trend_duration_days', 0) / 30) * 100)
        magnitude_score = min(100, (abs(opp.get('trend_change_pct', 0)) / 100) * 100)
        trend_health_component = ((macd_pos_score + duration_score + magnitude_score) / 3) * (weights['trendHealth'] / 100)
        volume_component = 0
        last_h4_cross = self.find_last_cross_info(h4_macd)
        if last_h4_cross and last_h4_cross['index'] > 0:
            idx = last_h4_cross['index']
            pullback_candles = h4_df.iloc[idx:]
            if len(pullback_candles) > 0 and idx >= len(pullback_candles):
                impulse_candles = h4_df.iloc[idx - len(pullback_candles):idx]
                pullback_avg_vol = pullback_candles['vol'].mean()
                impulse_avg_vol = impulse_candles['vol'].mean()
                if impulse_avg_vol > 0:
                    vol_contraction_score = max(0, (1 - (pullback_avg_vol / impulse_avg_vol))) * 100
                    volume_component = vol_contraction_score * (weights['volume'] / 100)
        h4_bands = self.calculate_bollinger_bands(h4_df)
        volatility_score = max(0, (1 - h4_bands.get('bandwidth', 1)) * 150)
        volatility_component = min(100, volatility_score) * (weights['volatility'] / 100)
        total_score = rs_component + trend_health_component + volume_component + volatility_component
        return round(total_score)
    
    def find_last_cross_info(self, macd_df):
        if len(macd_df) < 2: return None
        macds = macd_df.to_dict('records')
        last_cross_type = 'golden' if macds[-1]['macd'] > macds[-1]['signal'] else 'death'
        for i in range(len(macds) - 2, -1, -1):
            current_cross_type = 'golden' if macds[i]['macd'] > macds[i]['signal'] else 'death'
            if current_cross_type != last_cross_type:
                return {'type': last_cross_type, 'index': i + 1}
        return {'type': last_cross_type, 'index': 0}

    def find_last_dea_zero_cross_info(self, macd_df, lookback=100):
        if len(macd_df) < 2: return None
        macds = macd_df.to_dict('records')
        start = max(0, len(macds) - 1 - lookback)
        for i in range(len(macds) - 2, start -1, -1):
            if macds[i]['signal'] <= 0 and macds[i+1]['signal'] > 0:
                return {'type': 'bullish', 'index': i + 1}
            if macds[i]['signal'] >= 0 and macds[i+1]['signal'] < 0:
                return {'type': 'bearish', 'index': i + 1}
        return None

    def get_signal_freshness_info(self, df, macd_df, cross_type, atr_s):
        last_cross = self.find_last_cross_info(macd_df)
        if not last_cross or last_cross['type'] != cross_type:
            return {'is_fresh': False, 'reason': f"æœªæ‰¾åˆ°{cross_type}"}
        idx = last_cross['index']
        candles_ago = len(df) - 1 - idx
        if candles_ago > self.MAX_CANDLES_AGO:
            return {'is_fresh': False, 'reason': f"ä¿¡å·è¿‡ä¹…({candles_ago} > {self.MAX_CANDLES_AGO})"}
        if idx >= len(atr_s) or atr_s.empty:
            return {'is_fresh': False, 'reason': "ATRä¸è¶³"}
        signal_price = df['close'].iloc[idx]
        current_price = df['close'].iloc[-1]
        atr_at_signal = atr_s.iloc[idx]
        if atr_at_signal > 0 and abs(current_price - signal_price) > (self.ATR_MULTIPLIER * atr_at_signal):
            return {'is_fresh': False, 'reason': f"ä»·æ ¼æ³¢åŠ¨è¿‡å¤§(>{self.ATR_MULTIPLIER}å€ATR)"}
        return {'is_fresh': True, 'reason': 'æ–°é²œ'}

    def check_freshness_since_zero_cross(self, df, macd_df, cross_type, atr_s):
        zero_cross = self.find_last_dea_zero_cross_info(macd_df)
        if not zero_cross or zero_cross['type'] != cross_type:
            return {'is_fresh': False, 'reason': 'æœªæ‰¾åˆ°0è½´ç©¿è¶Š'}
        idx = zero_cross['index']
        if idx >= len(atr_s) or atr_s.empty:
            return {'is_fresh': False, 'reason': "ATRä¸è¶³"}
        cross_price = df['close'].iloc[idx]
        current_price = df['close'].iloc[-1]
        atr_at_cross = atr_s.iloc[idx]
        if atr_at_cross > 0 and abs(current_price - cross_price) > (self.ATR_MULTIPLIER * atr_at_cross):
            return {'is_fresh': False, 'reason': f"ç©¿è¶Š0è½´åä»·æ ¼æ³¢åŠ¨è¿‡å¤§(>{self.ATR_MULTIPLIER}å€ATR)"}
        return {'is_fresh': True, 'reason': 'ç©¿è¶Š0è½´ä¸”æ–°é²œ'}

    def analyze_instrument(self, inst_id, snapshot_data, is_historical=False):
        try:
            h1_df = self._parse_klines_to_df(snapshot_data['h1'])
            h4_df = self._parse_klines_to_df(snapshot_data['h4'])
            d1_df = self._parse_klines_to_df(snapshot_data['d1'])
            btc_d1_df = self._parse_klines_to_df(snapshot_data['btc']['d1'])
            eth_d1_df = self._parse_klines_to_df(snapshot_data['eth']['d1'])

            if len(h1_df) < 24 or len(d1_df) < 60: return None
            
            daily_volume = h1_df['volCcyQuote'].iloc[-24:].sum()
            if daily_volume < self.MACD_VOLUME_THRESHOLD: return None
            
            d1_macd = self.calculate_macd(d1_df['close'])
            h4_macd = self.calculate_macd(h4_df['close'])
            h1_macd = self.calculate_macd(h1_df['close'])
            d1_atr = self.calculate_atr(d1_df)
            h4_atr = self.calculate_atr(h4_df)
            if d1_macd.empty or h4_macd.empty or h1_macd.empty or d1_atr.empty or h4_atr.empty: return None
            
            rs_score = self.calculate_rs_score(d1_df, btc_d1_df, eth_d1_df)
            leader_score = self.calculate_market_leadership_score(d1_df, btc_d1_df, eth_d1_df)
            result_base = {'inst_id': inst_id, 'rs_score': rs_score, 'leader_score': leader_score, 'volume': daily_volume}
            
            # Add signal time and price for historical analysis
            if is_historical:
                result_base['signalTime'] = h1_df['ts'].iloc[-1]
                result_base['signalPrice'] = h1_df['close'].iloc[-1]

            dea_cross_info = self.find_last_dea_zero_cross_info(d1_macd)
            if dea_cross_info:
                idx = dea_cross_info['index']
                current_ts = result_base.get('signalTime', time.time() * 1000)
                result_base['trend_change_pct'] = ((d1_df['close'].iloc[-1] - d1_df['close'].iloc[idx]) / d1_df['close'].iloc[idx]) * 100
                result_base['trend_duration_days'] = (current_ts / 1000 - d1_df['ts'].iloc[idx]/1000) / (3600*24)
            
            d1_last, d1_prev = d1_macd.iloc[-1], d1_macd.iloc[-2]
            h4_last, h4_prev = h4_macd.iloc[-1], h4_macd.iloc[-2]
            h1_last, h1_prev = h1_macd.iloc[-1], h1_macd.iloc[-2]
            
            form_A_long_cross_info = self.find_last_dea_zero_cross_info(d1_macd, self.MAX_CANDLES_AGO)
            form_A_long = form_A_long_cross_info and form_A_long_cross_info['type'] == 'bullish'
            form_B_long_info = self.check_freshness_since_zero_cross(d1_df, d1_macd, 'bullish', d1_atr)
            momentum_C_long = d1_last['macd'] > d1_last['signal'] and d1_last['histogram'] > d1_prev['histogram']
            if (form_A_long or form_B_long_info['is_fresh']) and momentum_C_long:
                if h4_last['macd'] > h4_last['signal'] and h4_last['histogram'] > h4_prev['histogram']:
                    metrics = { 'volume': daily_volume, 'avg_volume': d1_df['volCcyQuote'].iloc[-20:].mean(), 'd1_hist': d1_last['histogram'], 'd1_prev_hist': d1_prev['histogram'], 'h4_hist': h4_last['histogram'], 'price': d1_df['close'].iloc[-1], 'ema60': d1_df['close'].ewm(span=60, adjust=False).mean().iloc[-1], 'bandwidth': self.calculate_bollinger_bands(d1_df).get('bandwidth', 1) }
                    score = self.calculate_startup_quality_score(result_base, metrics)
                    return {**result_base, 'type': 'Long Trend', 'quality_score': score}
                else:
                    return {**result_base, 'type': 'Long Watchlist', 'quality_score': None}

            form_A_short_cross_info = self.find_last_dea_zero_cross_info(d1_macd, self.MAX_CANDLES_AGO)
            form_A_short = form_A_short_cross_info and form_A_short_cross_info['type'] == 'bearish'
            form_B_short_info = self.check_freshness_since_zero_cross(d1_df, d1_macd, 'bearish', d1_atr)
            momentum_C_short = d1_last['macd'] < d1_last['signal'] and d1_last['histogram'] < d1_prev['histogram']
            if (form_A_short or form_B_short_info['is_fresh']) and momentum_C_short:
                if h4_last['macd'] < h4_last['signal'] and h4_last['histogram'] < h4_prev['histogram']:
                    metrics = { 'volume': daily_volume, 'avg_volume': d1_df['volCcyQuote'].iloc[-20:].mean(), 'd1_hist': d1_last['histogram'], 'd1_prev_hist': d1_prev['histogram'], 'h4_hist': h4_last['histogram'], 'price': d1_df['close'].iloc[-1], 'ema60': d1_df['close'].ewm(span=60, adjust=False).mean().iloc[-1], 'bandwidth': self.calculate_bollinger_bands(d1_df).get('bandwidth', 1) }
                    score = self.calculate_startup_quality_score(result_base, metrics)
                    return {**result_base, 'type': 'Short Trend', 'quality_score': score}
                else:
                    return {**result_base, 'type': 'Short Watchlist', 'quality_score': None}

            is_stable_bull = d1_last['macd'] > 0 and d1_last['signal'] > 0 and (d1_macd['signal'].iloc[-5:] > 0).all()
            if is_stable_bull:
                base_opp = None
                h4_fresh_info = self.get_signal_freshness_info(h4_df, h4_macd, 'golden', h4_atr)
                is_h1_golden_cross = h1_last['macd'] > h1_last['signal'] and h1_prev['macd'] <= h1_prev['signal']
                if h4_fresh_info['is_fresh'] and is_h1_golden_cross:
                    base_opp = {**result_base, 'type': 'Long Continuation', 'strategy_level': '4Hå»¶ç»­'}
                if not base_opp and is_h1_golden_cross and h4_last['histogram'] > h4_prev['histogram'] and h1_last['histogram'] > h1_prev['histogram']:
                    base_opp = {**result_base, 'type': 'Long Pullback', 'strategy_level': '1Hå›è°ƒ'}
                if base_opp:
                    base_opp['quality_score'] = self.calculate_continuation_quality_score(base_opp, d1_df, h4_df, d1_macd, h4_macd)
                    if dea_cross_info and dea_cross_info['type'] == 'bullish':
                        klines_since_cross = d1_df.iloc[dea_cross_info['index']:]
                        price_at_zero_cross = klines_since_cross['close'].iloc[0]
                        peak_price = klines_since_cross['high'].max()
                        initial_rally_range = peak_price - price_at_zero_cross
                        current_drawdown = peak_price - d1_df['close'].iloc[-1]
                        current_retracement_pct = (current_drawdown / initial_rally_range) * 100 if initial_rally_range > 0 else 0
                        if current_retracement_pct > 70:
                            initial_rally_pct = ((peak_price - price_at_zero_cross) / price_at_zero_cross) * 100
                            bands_history = d1_df['close'].rolling(20).std() / d1_df['close'].rolling(20).mean()
                            low_vol_threshold = bands_history.quantile(0.3)
                            if initial_rally_pct > 15 and self.calculate_bollinger_bands(d1_df).get('bandwidth', 1) < low_vol_threshold:
                                base_opp['type'] = 'Long Phoenix'
                    return base_opp

            is_stable_bear = d1_last['macd'] < 0 and d1_last['signal'] < 0 and (d1_macd['signal'].iloc[-5:] < 0).all()
            if is_stable_bear:
                base_opp = None
                h4_fresh_info = self.get_signal_freshness_info(h4_df, h4_macd, 'death', h4_atr)
                is_h1_death_cross = h1_last['macd'] < h1_last['signal'] and h1_prev['macd'] >= h1_prev['signal']
                if h4_fresh_info['is_fresh'] and is_h1_death_cross:
                    base_opp = {**result_base, 'type': 'Short Continuation', 'strategy_level': '4Hå»¶ç»­'}
                if not base_opp and is_h1_death_cross and h4_last['histogram'] < h4_prev['histogram'] and h1_last['histogram'] < h1_prev['histogram']:
                    base_opp = {**result_base, 'type': 'Short Pullback', 'strategy_level': '1Hå›è°ƒ'}
                if base_opp:
                    base_opp['quality_score'] = self.calculate_continuation_quality_score(base_opp, d1_df, h4_df, d1_macd, h4_macd)
                    return base_opp
            return None
        except Exception as e:
            return None

    def get_strategy_explanation(self):
        # ... [Same as previous version] ...
        return """
---
### **ç­–ç•¥è¯´æ˜**

#### **è¯„åˆ†ä½“ç³»**
- **ğŸ† å¸‚åœºé¢†è¢–åˆ† (Leader Score)**: ç»¼åˆè¯„ä¼°å¸ç§çš„â€œé¾™å¤´â€ç‰¹è´¨ã€‚åˆ†æ•°è¶Šé«˜ï¼Œé¾™å¤´ç›¸è¶Šå¼ºã€‚
  - **æ„æˆ**: ç›¸å¯¹å¼ºåº¦(40%), å›è°ƒæŠ—æ€§(30%), èµ„é‡‘æµ(20%), è¶‹åŠ¿è´¨é‡(10%).
- **ğŸš€ å¯åŠ¨ä¿¡å·è´¨é‡åˆ†**: è¡¡é‡è¶‹åŠ¿**èµ·ç‚¹**çš„å¼ºåº¦å’Œå¯é æ€§ã€‚
  - **æ„æˆ**: æˆäº¤é‡(30%), åŠ¨èƒ½(25%), ç›¸å¯¹å¼ºåº¦(15%), å‡çº¿è·ç¦»(15%), ç¡®è®¤åº¦(10%), æ³¢åŠ¨æ€§(5%).
- **â¡ï¸ å»¶ç»­/å›è°ƒè´¨é‡åˆ†**: è¡¡é‡åœ¨**å·²ç¡®ç«‹è¶‹åŠ¿ä¸­**ä»‹å…¥ç‚¹çš„â€œæ€§ä»·æ¯”â€ã€‚
  - **æ„æˆ**: ç›¸å¯¹å¼ºåº¦(40%), è¶‹åŠ¿å¥åº·åº¦(25%), å›è°ƒç¼©é‡(25%), æ³¢åŠ¨æ”¶ç¼©(10%).

#### **ä¿¡å·ç±»å‹å®šä¹‰**
- **ğŸ”¥ å‡¤å‡°ä¿¡å· (Phoenix)**: åœ¨é•¿æœŸå¤šå¤´è¶‹åŠ¿ä¸­ï¼Œæ•æ‰â€œæ·±åº¦å›è°ƒâ€ç»“æŸåçš„â€œé»„é‡‘å‘â€æœºä¼šã€‚
  - **æ ¸å¿ƒ**: ä»·æ ¼ä»è¶‹åŠ¿é«˜ç‚¹**å›æ’¤ > 70%**ï¼Œä¸”å‰æœŸæ¶¨å¹… > 15%ï¼Œå›è°ƒæœ«ç«¯æ³¢åŠ¨ç‡æ”¶ç¼©ã€‚
- **ğŸš€ å¯åŠ¨ (Trend)**: æ•æ‰è¶‹åŠ¿åè½¬çš„èµ·ç‚¹ã€‚
  - **æ¡ä»¶**: æ—¥çº¿çº§åˆ«â€œæ–°é²œâ€ç©¿è¶Š0è½´ + åŠ¨èƒ½å…±æŒ¯ + 4å°æ—¶å‘¨æœŸç¡®è®¤ã€‚
- **â¡ï¸ å»¶ç»­ (Continuation)**: åœ¨å¼ºè¶‹åŠ¿ä¸­ï¼Œæ•æ‰ä¸­æœŸ(4H)å›è°ƒç»“æŸåçš„æœ€å¼ºç¡®è®¤ç‚¹ã€‚
  - **æ¡ä»¶**: æ—¥çº¿0è½´ä¸Š/ä¸‹ç¨³å®š + 4å°æ—¶æ–°é²œé‡‘å‰/æ­»å‰ + 1å°æ—¶åˆšåˆšé‡‘å‰/æ­»å‰ç¡®è®¤ã€‚
- **ğŸ‚ å›è°ƒ (Pullback)**: åœ¨å¼ºè¶‹åŠ¿ä¸­ï¼Œæ•æ‰çŸ­æœŸ(1H)å›è°ƒç»“æŸåçš„æœ€æ—©å…¥åœºç‚¹ã€‚
  - **æ¡ä»¶**: æ—¥çº¿0è½´ä¸Š/ä¸‹ç¨³å®š + 4å°æ—¶å›è°ƒåŠ¨èƒ½è¡°ç«­ + 1å°æ—¶åˆšåˆšé‡‘å‰/æ­»å‰ä¸”åŠ¨èƒ½å¢å¼ºã€‚
"""
    
    def format_volume(self, volume):
        if volume >= 1_000_000_000: return f"{volume/1_000_000_000:.2f}B"
        if volume >= 1_000_000: return f"{volume/1_000_000:.2f}M"
        if volume >= 1_000: return f"{volume/1_000:.2f}K"
        return f"{volume:.2f}"
    
    def get_market_sentiment(self, btc_data):
        # ... [Same as previous version] ...
        klines = {
            '1D': self._parse_klines_to_df(btc_data['d1'])['close'],
            '4H': self._parse_klines_to_df(btc_data['h4'])['close'],
            '1H': self._parse_klines_to_df(btc_data['h1'])['close']
        }
        macds = {tf: self.calculate_macd(prices) for tf, prices in klines.items()}
        if any(m.empty for m in macds.values()): return {'sentiment': 'Neutral', 'text':"BTCæ•°æ®ä¸è¶³", 'details': ''}

        score, bull_points, bear_points = 0, [], []
        weights = {'1D': 2, '4H': 1, '1H': 0.5}

        for tf in ['1D', '4H', '1H']:
            last, prev = macds[tf].iloc[-1], macds[tf].iloc[-2]
            tf_text = f"**{tf}**:"
            if last['macd'] > 0 and last['signal'] > 0: score += 1 * weights[tf]; bull_points.append(f"{tf_text} åŒçº¿ä½äº0è½´ä¹‹ä¸Š")
            if last['macd'] < 0 and last['signal'] < 0: score -= 1 * weights[tf]; bear_points.append(f"{tf_text} åŒçº¿ä½äº0è½´ä¹‹ä¸‹")
            
            if last['macd'] > last['signal']:
                score += 0.5 * weights[tf]
                point = f"{tf_text} é‡‘å‰"
                if last['histogram'] > prev['histogram']: point += "ä¸”å¤šå¤´åŠ¨èƒ½å¢å¼º"
                else: point += "ä½†å¤šå¤´åŠ¨èƒ½å‡å¼±"
                bull_points.append(point)
            else:
                score -= 0.5 * weights[tf]
                point = f"{tf_text} æ­»å‰"
                if last['histogram'] < prev['histogram']: point += "ä¸”ç©ºå¤´åŠ¨èƒ½å¢å¼º"
                else: point += "ä½†ç©ºå¤´åŠ¨èƒ½å‡å¼±"
                bear_points.append(point)

        if score >= 3.5: sentiment, text = 'Bullish', "å¼ºåŠ¿çœ‹æ¶¨ ğŸ‚"
        elif score >= 1.5: sentiment, text = 'Bullish', "éœ‡è¡åå¤š ğŸ“ˆ"
        elif score <= -3.5: sentiment, text = 'Bearish', "å¼ºåŠ¿çœ‹ç©º ğŸ»"
        elif score <= -1.5: sentiment, text = 'Bearish', "éœ‡è¡åç©º ğŸ“‰"
        else: sentiment, text = 'Neutral', "å¤šç©ºèƒ¶ç€ íš¡ë³´"
        
        details = ""
        if bull_points:
            details += "#### ğŸ‚ çœ‹å¤šç†ç”±\n- " + "\n- ".join(bull_points)
        if bear_points:
            details += "\n\n#### ğŸ» çœ‹ç©ºç†ç”±\n- " + "\n- ".join(bear_points)

        return {'sentiment': sentiment, 'text': text, 'details': details.strip()}

    def load_watchlist_state(self):
        if not os.path.exists(self.state_file): return {}
        try:
            with open(self.state_file, 'r') as f: return json.load(f)
        except: return {}

    def save_watchlist_state(self, watchlist):
        try:
            with open(self.state_file, 'w') as f: json.dump(watchlist, f)
        except Exception as e: print(f"ä¿å­˜çŠ¶æ€æ–‡ä»¶å¤±è´¥: {e}")

    # --- Backtesting and Reporting ---
    def analyze_signal_performance(self, signal):
        now = time.time() * 1000
        time_since_signal_ms = now - signal['signalTime']
        minutes_since_signal = time_since_signal_ms / (1000 * 60)
        
        # Fetch 5-minute candles to cover the period since the signal
        candles_to_fetch = min(300, int(minutes_since_signal / 5) + 1)
        if candles_to_fetch <= 0:
            return {'maxMovePct': 0, 'timeToPeak': '0m'}

        klines_5m_raw = self.get_kline_data(signal['inst_id'], '5m', candles_to_fetch)
        if not klines_5m_raw:
            return {'maxMovePct': None, 'timeToPeak': 'N/A'}

        klines_5m_df = self._parse_klines_to_df(klines_5m_raw)
        relevant_klines = klines_5m_df[klines_5m_df['ts'] > signal['signalTime']]

        if relevant_klines.empty:
            return {'maxMovePct': 0, 'timeToPeak': '0m'}

        peak_price, peak_time = 0, 0
        if 'Long' in signal['type']:
            peak_price = relevant_klines['high'].max()
            peak_candle = relevant_klines.loc[relevant_klines['high'].idxmax()]
            peak_time = peak_candle['ts']
        else: # Short
            peak_price = relevant_klines['low'].min()
            peak_candle = relevant_klines.loc[relevant_klines['low'].idxmin()]
            peak_time = peak_candle['ts']
            
        max_move_pct = ((peak_price - signal['signalPrice']) / signal['signalPrice']) * 100
        time_to_peak_mins = round((peak_time - signal['signalTime']) / (1000 * 60))

        return {'maxMovePct': max_move_pct, 'timeToPeak': f"{time_to_peak_mins}m"}

    def create_backtest_report(self, historical_signals):
        if not historical_signals:
            return "### ğŸ“Š è¿‡å»12å°æ—¶ä¿¡å·å›æµ‹ ğŸ“Š\n\nåœ¨è¿‡å»12å°æ—¶å†…æœªå‘ç°ç¬¦åˆç­–ç•¥çš„äº¤æ˜“ä¿¡å·ã€‚\n"

        report = "### ğŸ“Š è¿‡å»12å°æ—¶ä¿¡å·å›æµ‹ ğŸ“Š\n"
        
        type_map = { 'Long Trend': 'ğŸš€ å¤šå¤´å¯åŠ¨', 'Long Phoenix': 'ğŸ”¥ å‡¤å‡°ä¿¡å·', 'Long Continuation': 'â¡ï¸ å¤šå¤´å»¶ç»­', 'Long Pullback': 'ğŸ‚ å¤šå¤´å›è°ƒ', 'Short Trend': 'ğŸ“‰ ç©ºå¤´å¯åŠ¨', 'Short Continuation': 'â†˜ï¸ ç©ºå¤´å»¶ç»­', 'Short Pullback': 'ğŸ» ç©ºå¤´å›è°ƒ' }

        # Group signals by instrument
        grouped_signals = {}
        for sig in historical_signals:
            inst_name = sig['inst_id'].replace('-USDT-SWAP', '')
            if inst_name not in grouped_signals:
                grouped_signals[inst_name] = []
            grouped_signals[inst_name].append(sig)

        # Sort groups by the most recent signal time within the group
        sorted_groups = sorted(grouped_signals.items(), key=lambda item: max(s['signalTime'] for s in item[1]), reverse=True)

        for inst_name, signals in sorted_groups:
            report += f"\n#### **{inst_name}** ({len(signals)}æ¡ä¿¡å·)\n"
            report += "| æœ‰æ•ˆæ€§ | é¢†è¢–åˆ† | è´¨é‡åˆ† | ä¿¡å·æ—¶é—´ | ç±»å‹ | RSåˆ† | ä¿¡å·ä»· | æœ€å¤§æ¶¨/è·Œå¹… | è¾¾å³°è€—æ—¶ |\n"
            report += "|:---:|:---:|:---:|:---|:---|:---:|:---:|:---:|:---:|\n"
            
            signals.sort(key=lambda x: x['signalTime'], reverse=True) # Sort signals for each instrument
            
            for sig in signals:
                perf = sig.get('performance', {})
                max_move = perf.get('maxMovePct')
                is_effective = "N/A"
                if max_move is not None:
                    if 'Long' in sig['type'] and max_move > 0.2: is_effective = "âœ… æœ‰æ•ˆ"
                    elif 'Short' in sig['type'] and max_move < -0.2: is_effective = "âœ… æœ‰æ•ˆ"
                    else: is_effective = "âŒ æ— æ•ˆ"
                
                move_str = "æŸ¥è¯¢å¤±è´¥"
                if max_move is not None:
                    move_str = f"ğŸ“ˆ {max_move:.2f}%" if max_move > 0 else f"ğŸ“‰ {max_move:.2f}%"

                sig_time = datetime.fromtimestamp(sig['signalTime']/1000, self.timezone).strftime('%H:%M')
                time_ago = f"({sig['hoursAgo']}Hå‰)"
                
                leader_score = sig.get('leader_score') or 'N/A'
                quality_score = sig.get('quality_score') or 'N/A'
                rs_score = sig.get('rs_score') or 'N/A'

                report += f"| {is_effective} | {leader_score} | {quality_score} | {sig_time} {time_ago} | {type_map.get(sig['type'], sig['type'])} | {rs_score} | {sig['signalPrice']:.4g} | {move_str} | {perf.get('timeToPeak', 'N/A')} |\n"
                
        return report

    def create_opportunity_report(self, backtest_report, opportunities, market_info, upgraded_signals):
        opportunities.sort(key=lambda x: x.get('leader_score', 0) or 0, reverse=True)
        upgraded_signals.sort(key=lambda x: x.get('leader_score', 0) or 0, reverse=True)
        type_map = { 'Long Trend': 'ğŸš€ å¤šå¤´å¯åŠ¨', 'Long Phoenix': 'ğŸ”¥ å‡¤å‡°ä¿¡å·', 'Long Continuation': 'â¡ï¸ å¤šå¤´å»¶ç»­', 'Long Pullback': 'ğŸ‚ å¤šå¤´å›è°ƒ', 'Long Watchlist': 'ğŸ‘€ å¤šå¤´è§‚å¯Ÿ', 'Short Trend': 'ğŸ“‰ ç©ºå¤´å¯åŠ¨', 'Short Continuation': 'â†˜ï¸ ç©ºå¤´å»¶ç»­', 'Short Pullback': 'ğŸ» ç©ºå¤´å›è°ƒ', 'Short Watchlist': 'ğŸ‘€ ç©ºå¤´è§‚å¯Ÿ' }
        
        content = f"{backtest_report}\n---\n"
        content += f"### ğŸ”¥ å½“å‰æœ€æ–°æœºä¼šä¿¡å·\n"
        content += f"**å¸‚åœºæƒ…ç»ª: {market_info.get('text', 'N/A')}**\n\n{market_info.get('details', '')}\n"

        def generate_table(title, opp_list):
            if not opp_list: return ""
            table = f"### {title}\n"
            table += "| é¢†è¢–åˆ† | è´¨é‡åˆ† | RSåˆ† | äº¤æ˜“å¯¹ | æœºä¼šç±»å‹ | è¶‹åŠ¿å¹…åº¦ | è¶‹åŠ¿æ—¶é•¿ | 24Hæˆäº¤é¢ | 24Hæ¶¨è·Œå¹… |\n"
            table += "|:---:|:---:|:---:|:---|:---|:---:|:---:|:---:|:---:|\n"
            for opp in opp_list:
                inst_name = opp['inst_id'].replace('-USDT-SWAP', '')
                opp_type = type_map.get(opp['type'], 'æœªçŸ¥')
                vol_str = self.format_volume(opp['volume'])
                change_24h = opp.get('price_change_24h', 0)
                change_24h_str = f"ğŸ“ˆ {change_24h:.2f}%" if change_24h > 0 else f"ğŸ“‰ {change_24h:.2f}%"
                leader_score = f"**{opp.get('leader_score', 'N/A')}**" if opp.get('leader_score', 0) >= 80 else str(opp.get('leader_score', 'N/A'))
                quality_score = f"**{opp.get('quality_score', 'N/A')}**" if opp.get('quality_score', 0) >= 80 else str(opp.get('quality_score', 'N/A'))
                rs_score = f"**{opp.get('rs_score', 'N/A')}**" if opp.get('rs_score', 0) >= 80 else str(opp.get('rs_score', 'N/A'))
                trend_change = opp.get('trend_change_pct', 0)
                trend_change_str = f"ğŸ“ˆ {trend_change:.1f}%" if trend_change > 0 else (f"ğŸ“‰ {trend_change:.1f}%" if trend_change < 0 else "N/A")
                trend_days = opp.get('trend_duration_days', 0)
                trend_days_str = f"{trend_days:.1f}å¤©" if trend_days > 0 else "N/A"
                warning = " (é€†å¤§ç›˜)" if (market_info['sentiment'] == 'Bullish' and 'Short' in opp['type']) or \
                                      (market_info['sentiment'] == 'Bearish' and 'Long' in opp['type']) else ""
                table += f"| {leader_score} | {quality_score} | {rs_score} | **{inst_name}** | {opp_type}{warning} | {trend_change_str} | {trend_days_str} | {vol_str} | {change_24h_str} |\n"
            return table

        upgraded_ids = {s['inst_id'] for s in upgraded_signals}
        new_actionable = [opp for opp in opportunities if opp['inst_id'] not in upgraded_ids]
        if upgraded_signals:
            content += generate_table('âœ¨ ä¿¡å·å‡çº§ âœ¨ (æŒ‰é¢†è¢–åˆ†æ’åº)', upgraded_signals)
        if new_actionable:
            content += generate_table('ğŸ’ æ–°æœºä¼šä¿¡å· (æŒ‰é¢†è¢–åˆ†æ’åº)', new_actionable)
        content += self.get_strategy_explanation()
        return content

    def run_backtest(self, all_instruments_data):
        print(f"[{self.get_current_time_str()}] === å¼€å§‹æ‰§è¡Œ12å°æ—¶ä¿¡å·å›æµ‹ ===")
        historical_signals = []
        unique_signal_checker = set()
        
        btc_full_history = all_instruments_data.get('BTC-USDT-SWAP')
        eth_full_history = all_instruments_data.get('ETH-USDT-SWAP')
        if not btc_full_history or not eth_full_history:
            print("BTCæˆ–ETHæ•°æ®ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œå›æµ‹ã€‚")
            return ""

        for i in range(1, 13): # For the last 12 hours
            print(f"\ræ­£åœ¨å›æº¯è¿‡å»ç¬¬ {i}/12 å°æ—¶çš„ä¿¡å·...", end="")
            for inst_id, data in all_instruments_data.items():
                if not data['h1'] or len(data['h1']) <= i: continue

                # Create historical data snapshot
                historical_snapshot = {
                    'h1': data['h1'][:-i],
                    'h4': data['h4'][:-floor(i/4)] if len(data['h4']) > floor(i/4) else [],
                    'd1': data['d1'][:-floor(i/24)] if len(data['d1']) > floor(i/24) else [],
                    'btc': {'d1': btc_full_history['d1'][:-floor(i/24)] if len(btc_full_history['d1']) > floor(i/24) else []},
                    'eth': {'d1': eth_full_history['d1'][:-floor(i/24)] if len(eth_full_history['d1']) > floor(i/24) else []}
                }
                
                signal = self.analyze_instrument(inst_id, historical_snapshot, is_historical=True)

                if signal and 'Watchlist' not in signal['type']:
                    unique_id = f"{signal['inst_id']}-{signal['type']}-{signal['signalTime']}"
                    if unique_id not in unique_signal_checker:
                        signal['hoursAgo'] = i
                        historical_signals.append(signal)
                        unique_signal_checker.add(unique_id)
        
        print(f"\n[{self.get_current_time_str()}] å›æµ‹å®Œæˆï¼Œå‘ç° {len(historical_signals)} ä¸ªå†å²ä¿¡å·ã€‚")

        if historical_signals:
            print(f"[{self.get_current_time_str()}] æ­£åœ¨å¹¶å‘åˆ†æ {len(historical_signals)} ä¸ªå†å²ä¿¡å·çš„è¡¨ç°...")
            with ThreadPoolExecutor(max_workers=self.STRICT_CONCURRENCY_LIMIT) as executor:
                future_to_signal = {executor.submit(self.analyze_signal_performance, sig): sig for sig in historical_signals}
                for i, future in enumerate(as_completed(future_to_signal)):
                    signal = future_to_signal[future]
                    try:
                        performance_data = future.result()
                        signal['performance'] = performance_data
                        print(f"\rä¿¡å·è¡¨ç°åˆ†æè¿›åº¦: {i+1}/{len(historical_signals)}", end="")
                    except Exception as exc:
                        print(f'{signal["inst_id"]} ç”Ÿæˆè¡¨ç°æ—¶å‡ºé”™: {exc}')
            print(f"\n[{self.get_current_time_str()}] å†å²ä¿¡å·è¡¨ç°åˆ†æå®Œæˆã€‚")

        return self.create_backtest_report(historical_signals)

    # --- ä¸»è¿è¡Œå‡½æ•° ---
    def run(self):
        start_time = time.time()
        print(f"[{self.get_current_time_str()}] === å¼€å§‹æ‰§è¡Œç›‘æ§ä»»åŠ¡ ===")
        
        previous_watchlist = self.load_watchlist_state()
        instruments = self.get_perpetual_instruments()
        if not instruments: return
        
        print(f"[{self.get_current_time_str()}] æ­£åœ¨å¹¶å‘è·å– {len(instruments)} ä¸ªå¸ç§çš„Kçº¿æ•°æ®...")
        all_instruments_data = {}
        with ThreadPoolExecutor(max_workers=self.CONCURRENCY_LIMIT) as executor:
            futures = [executor.submit(self.fetch_all_data_for_instrument, inst) for inst in instruments]
            for i, future in enumerate(as_completed(futures)):
                inst_id, data = future.result()
                if data:
                    all_instruments_data[inst_id] = data
                print(f"\ræ•°æ®è·å–è¿›åº¦: {i+1}/{len(instruments)}", end="")
        print(f"\n[{self.get_current_time_str()}] æ•°æ®è·å–å®Œæ¯•ï¼Œè€—æ—¶ {time.time() - start_time:.2f}ç§’. æœ‰æ•ˆæ•°æ®: {len(all_instruments_data)}ä¸ªå¸ç§ã€‚")

        # <<< NEW: Run backtest first >>>
        backtest_report = self.run_backtest(all_instruments_data)
        
        print(f"[{self.get_current_time_str()}] === å¼€å§‹æ‰§è¡Œå½“å‰ä¿¡å·æ‰«æ ===")
        btc_data = all_instruments_data.get('BTC-USDT-SWAP')
        if not btc_data:
            print("æœªèƒ½è·å–BTCæ•°æ®ï¼Œä»»åŠ¡ç»ˆæ­¢ã€‚")
            return
            
        market_info = self.get_market_sentiment(btc_data)
        print(f"[{self.get_current_time_str()}] å½“å‰å¸‚åœºæƒ…ç»ª: {market_info['text']}")
        
        all_opportunities = []
        with ThreadPoolExecutor(max_workers=os.cpu_count() or 4) as executor:
            # Prepare current data snapshots
            current_snapshots = {}
            btc_d1, eth_d1 = all_instruments_data['BTC-USDT-SWAP']['d1'], all_instruments_data['ETH-USDT-SWAP']['d1']
            for inst_id, data in all_instruments_data.items():
                current_snapshots[inst_id] = {**data, 'btc': {'d1': btc_d1}, 'eth': {'d1': eth_d1}}

            futures = [executor.submit(self.analyze_instrument, inst_id, snap, is_historical=False) for inst_id, snap in current_snapshots.items()]
            for i, future in enumerate(as_completed(futures)):
                result = future.result()
                if result:
                    all_opportunities.append(result)
        print(f"[{self.get_current_time_str()}] ä¿¡å·åˆ†æå®Œæ¯•ï¼Œå‘ç° {len(all_opportunities)} ä¸ªæ½œåœ¨ä¿¡å·ã€‚")

        if all_opportunities:
            print(f"[{self.get_current_time_str()}] æ­£åœ¨è·å– {len(all_opportunities)} ä¸ªä¿¡å·å¸ç§çš„24Hæ¶¨è·Œå¹…...")
            with ThreadPoolExecutor(max_workers=self.CONCURRENCY_LIMIT) as executor:
                ticker_futures = {executor.submit(self.get_ticker_data, opp['inst_id']): opp for opp in all_opportunities}
                for future in as_completed(ticker_futures):
                    opp = ticker_futures[future]
                    ticker_data = future.result()
                    opp['price_change_24h'] = ticker_data.get('price_change_24h', 0)

            upgraded_signals, new_watchlist, actionable_opportunities = [], {}, []
            for opp in all_opportunities:
                inst_id, opp_type = opp['inst_id'], opp['type']
                if 'Watchlist' not in opp_type:
                    actionable_opportunities.append(opp)
                    if inst_id in previous_watchlist:
                        upgraded_signals.append(opp)
                        print(f"[{self.get_current_time_str()}] âœ¨ ä¿¡å·å‡çº§: {inst_id} ä» {previous_watchlist[inst_id]} å‡çº§ä¸º {opp_type}")
                if 'Watchlist' in opp_type:
                    new_watchlist[inst_id] = opp_type
            
            self.save_watchlist_state(new_watchlist)
            
            if actionable_opportunities:
                title = ""
                new_actionable_count = len(actionable_opportunities) - len(upgraded_signals)
                if upgraded_signals:
                    title += f"âœ¨ {len(upgraded_signals)}ä¸ªå‡çº§"
                    if new_actionable_count > 0:
                        title += f" + {new_actionable_count}ä¸ªæ–°æœºä¼š"
                else:
                    title = f"ğŸ’ å‘ç° {len(actionable_opportunities)} ä¸ªæ–°æœºä¼š"
                
                content = self.create_opportunity_report(backtest_report, actionable_opportunities, market_info, upgraded_signals)
                self.send_notification(title, content)
            else:
                print(f"[{self.get_current_time_str()}] ä»…å‘ç° {len(all_opportunities)} ä¸ªè§‚å¯Ÿä¿¡å·ï¼Œä¸å‘é€é€šçŸ¥ã€‚")
        else:
            print(f"[{self.get_current_time_str()}] æœ¬æ¬¡æœªå‘ç°ä»»ä½•ç¬¦åˆæ¡ä»¶çš„å®æ—¶ä¿¡å·ã€‚")
            self.save_watchlist_state({}) # Clear watchlist if no current signals are found
            # Still send a notification with the backtest results if any were found
            if "æœªå‘ç°" not in backtest_report:
                self.send_notification("OKX 12å°æ—¶ç­–ç•¥å›æµ‹æŠ¥å‘Š", backtest_report + self.get_strategy_explanation())

        end_time = time.time()
        print(f"[{self.get_current_time_str()}] === ç›‘æ§ä»»åŠ¡æ‰§è¡Œå®Œæ¯•ï¼Œæ€»è€—æ—¶: {end_time - start_time:.2f}ç§’ ===")

if __name__ == "__main__":
    monitor = OKXMonitor()
    monitor.run()
